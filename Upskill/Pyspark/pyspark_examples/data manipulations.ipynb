{"cells":[{"cell_type":"code","source":["l = [('X' , )]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ec163f30-ff14-4151-ab8c-c510f75413ce","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = spark.createDataFrame(l , \"dummy STRING\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a6de0d7d-4f3c-4b09-9beb-bdfd84e797b6","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df.printSchema"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f645c24f-d48b-4f7d-8a40-7c2b13b31ee7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Out[3]: <bound method DataFrame.printSchema of DataFrame[dummy: string]>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[3]: <bound method DataFrame.printSchema of DataFrame[dummy: string]>"]}}],"execution_count":0},{"cell_type":"code","source":["df.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1f7cc86e-890d-4995-acd9-3b0b4d85019a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----+\n|dummy|\n+-----+\n|    X|\n+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----+\n|dummy|\n+-----+\n|    X|\n+-----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import current_date\ndf.select(current_date().alias(\"today's_date\")). \\\nshow()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"eedfa9f4-893a-4126-b1d3-6aef1c6fbd60","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+------------+\n|today's_date|\n+------------+\n|  2023-02-15|\n+------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------------+\n|today's_date|\n+------------+\n|  2023-02-15|\n+------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["employees = [\n(1, \"Scott\", \"Tiger\", 1000.0,\n\"united states\", \"+1 123 456 7890\", \"123 45 6789\"\n),\n(2, \"Henry\", \"Ford\",  1250.0,\n\"India\", \"+91 234 567 8901\", \"456 78 9123\"\n),\n(3, \"Nick\", \"Junior\", 750.0,\n\"united KINGDOM\", \"+44 111 111 1111\", \"222 33 4444\"\n),\n(4, \"Bill\", \"Gomes\", 1590.0,\n\"AUSTRALIA\", \"+61 987 654 3210\", \"789 12 6118\"\n)\n]\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b7f04871-2428-4818-a98b-68dbe5d58d2b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["employeeDF = spark.createDataFrame(employees, \n                                  schema= \"\"\"employee_id INT , first_name STRING, last_name STRING,\n                                  salary FLOAT, nationality STRING, phone_number STRING , ssn STRING\"\"\" )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b252a927-16f4-4142-8707-b80134f87634","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["employeeDF.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d1dffb64-efa7-41cc-a1d6-c34afcb547b1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+----------+---------+------+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n|          4|      Bill|    Gomes|1590.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+----------+---------+------+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n|          4|      Bill|    Gomes|1590.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["help(current_date())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"36031cda-9383-424c-b296-bceada77636b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Help on Column in module pyspark.sql.column object:\n\nclass Column(builtins.object)\n |  Column(jc: py4j.java_gateway.JavaObject) -> None\n |  \n |  A column in a DataFrame.\n |  \n |  :class:`Column` instances can be created by::\n |  \n |      # 1. Select a column out of a DataFrame\n |  \n |      df.colName\n |      df[\"colName\"]\n |  \n |      # 2. Create from an expression\n |      df.colName + 1\n |      1 / df.colName\n |  \n |  .. versionadded:: 1.3.0\n |  \n |  Methods defined here:\n |  \n |  __add__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __and__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __bool__ = __nonzero__(self) -> None\n |  \n |  __contains__(self, item: Any) -> None\n |      # container operators\n |  \n |  __div__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __eq__(self, other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary function\n |  \n |  __ge__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __getattr__(self, item: Any) -> 'Column'\n |  \n |  __getitem__(self, k: Any) -> 'Column'\n |  \n |  __gt__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __init__(self, jc: py4j.java_gateway.JavaObject) -> None\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  __invert__ = _(self: 'Column') -> 'Column'\n |  \n |  __iter__(self) -> None\n |  \n |  __le__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __lt__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __mod__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __mul__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __ne__(self, other: Any) -> 'Column'\n |      binary function\n |  \n |  __neg__ = _(self: 'Column') -> 'Column'\n |  \n |  __nonzero__(self) -> None\n |  \n |  __or__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __pow__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral')]) -> 'Column'\n |      binary function\n |  \n |  __radd__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __rand__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __rdiv__ = _(self: 'Column', other: Union[ForwardRef('LiteralType'), ForwardRef('DecimalLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __repr__(self) -> str\n |      Return repr(self).\n |  \n |  __rmod__ = _(self: 'Column', other: Union[ForwardRef('LiteralType'), ForwardRef('DecimalLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __rmul__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __ror__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __rpow__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral')]) -> 'Column'\n |      binary function\n |  \n |  __rsub__ = _(self: 'Column', other: Union[ForwardRef('LiteralType'), ForwardRef('DecimalLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __rtruediv__ = _(self: 'Column', other: Union[ForwardRef('LiteralType'), ForwardRef('DecimalLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __sub__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __truediv__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  alias(self, *alias: str, **kwargs: Any) -> 'Column'\n |      Returns this column aliased with a new name or names (in the case of expressions that\n |      return more than one column, such as explode).\n |      \n |      .. versionadded:: 1.3.0\n |      \n |      Parameters\n |      ----------\n |      alias : str\n |          desired column names (collects all positional arguments passed)\n |      \n |      Other Parameters\n |      ----------------\n |      metadata: dict\n |          a dict of information to be stored in ``metadata`` attribute of the\n |          corresponding :class:`StructField <pyspark.sql.types.StructField>` (optional, keyword\n |          only argument)\n |      \n |          .. versionchanged:: 2.2.0\n |             Added optional ``metadata`` argument.\n |      \n |      Examples\n |      --------\n |      >>> df.select(df.age.alias(\"age2\")).collect()\n |      [Row(age2=2), Row(age2=5)]\n |      >>> df.select(df.age.alias(\"age3\", metadata={'max': 99})).schema['age3'].metadata['max']\n |      99\n |  \n |  asc = _(self: 'Column') -> 'Column'\n |      Returns a sort expression based on ascending order of the column.\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([('Tom', 80), ('Alice', None)], [\"name\", \"height\"])\n |      >>> df.select(df.name).orderBy(df.name.asc()).collect()\n |      [Row(name='Alice'), Row(name='Tom')]\n |  \n |  asc_nulls_first = _(self: 'Column') -> 'Column'\n |      Returns a sort expression based on ascending order of the column, and null values\n |      return before non-null values.\n |      \n |      .. versionadded:: 2.4.0\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], [\"name\", \"height\"])\n |      >>> df.select(df.name).orderBy(df.name.asc_nulls_first()).collect()\n |      [Row(name=None), Row(name='Alice'), Row(name='Tom')]\n |  \n |  asc_nulls_last = _(self: 'Column') -> 'Column'\n |      Returns a sort expression based on ascending order of the column, and null values\n |      appear after non-null values.\n |      \n |      .. versionadded:: 2.4.0\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], [\"name\", \"height\"])\n |      >>> df.select(df.name).orderBy(df.name.asc_nulls_last()).collect()\n |      [Row(name='Alice'), Row(name='Tom'), Row(name=None)]\n |  \n |  astype = cast(self, dataType)\n |      :func:`astype` is an alias for :func:`cast`.\n |      \n |      .. versionadded:: 1.4\n |  \n |  between(self, lowerBound: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DateTimeLiteral'), ForwardRef('DecimalLiteral')], upperBound: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DateTimeLiteral'), ForwardRef('DecimalLiteral')]) -> 'Column'\n |      True if the current column is between the lower bound and upper bound, inclusive.\n |      \n |      .. versionadded:: 1.3.0\n |      \n |      Examples\n |      --------\n |      >>> df.select(df.name, df.age.between(2, 4)).show()\n |      +-----+---------------------------+\n |      | name|((age >= 2) AND (age <= 4))|\n |      +-----+---------------------------+\n |      |Alice|                       true|\n |      |  Bob|                      false|\n |      +-----+---------------------------+\n |  \n |  bitwiseAND = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      Compute bitwise AND of this expression with another expression.\n |      \n |      Parameters\n |      ----------\n |      other\n |          a value or :class:`Column` to calculate bitwise and(&) with\n |          this :class:`Column`.\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([Row(a=170, b=75)])\n |      >>> df.select(df.a.bitwiseAND(df.b)).collect()\n |      [Row((a & b)=10)]\n |  \n |  bitwiseOR = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      Compute bitwise OR of this expression with another expression.\n |      \n |      Parameters\n |      ----------\n |      other\n |          a value or :class:`Column` to calculate bitwise or(|) with\n |          this :class:`Column`.\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([Row(a=170, b=75)])\n |      >>> df.select(df.a.bitwiseOR(df.b)).collect()\n |      [Row((a | b)=235)]\n |  \n |  bitwiseXOR = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      Compute bitwise XOR of this expression with another expression.\n |      \n |      Parameters\n |      ----------\n |      other\n |          a value or :class:`Column` to calculate bitwise xor(^) with\n |          this :class:`Column`.\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([Row(a=170, b=75)])\n |      >>> df.select(df.a.bitwiseXOR(df.b)).collect()\n |      [Row((a ^ b)=225)]\n |  \n |  cast(self, dataType: Union[pyspark.sql.types.DataType, str]) -> 'Column'\n |      Casts the column into type ``dataType``.\n |      \n |      .. versionadded:: 1.3.0\n |      \n |      Examples\n |      --------\n |      >>> df.select(df.age.cast(\"string\").alias('ages')).collect()\n |      [Row(ages='2'), Row(ages='5')]\n |      >>> df.select(df.age.cast(StringType()).alias('ages')).collect()\n |      [Row(ages='2'), Row(ages='5')]\n |  \n |  contains = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      Contains the other element. Returns a boolean :class:`Column` based on a string match.\n |      \n |      Parameters\n |      ----------\n |      other\n |          string in line. A value as a literal or a :class:`Column`.\n |      \n |      Examples\n |      --------\n |      >>> df.filter(df.name.contains('o')).collect()\n |      [Row(age=5, name='Bob')]\n |  \n |  desc = _(self: 'Column') -> 'Column'\n |      Returns a sort expression based on the descending order of the column.\n |      \n |      .. versionadded:: 2.4.0\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([('Tom', 80), ('Alice', None)], [\"name\", \"height\"])\n |      >>> df.select(df.name).orderBy(df.name.desc()).collect()\n |      [Row(name='Tom'), Row(name='Alice')]\n |  \n |  desc_nulls_first = _(self: 'Column') -> 'Column'\n |      Returns a sort expression based on the descending order of the column, and null values\n |      appear before non-null values.\n |      \n |      .. versionadded:: 2.4.0\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], [\"name\", \"height\"])\n |      >>> df.select(df.name).orderBy(df.name.desc_nulls_first()).collect()\n |      [Row(name=None), Row(name='Tom'), Row(name='Alice')]\n |  \n |  desc_nulls_last = _(self: 'Column') -> 'Column'\n |      Returns a sort expression based on the descending order of the column, and null values\n |      appear after non-null values.\n |      \n |      .. versionadded:: 2.4.0\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], [\"name\", \"height\"])\n |      >>> df.select(df.name).orderBy(df.name.desc_nulls_last()).collect()\n |      [Row(name='Tom'), Row(name='Alice'), Row(name=None)]\n |  \n |  dropFields(self, *fieldNames: str) -> 'Column'\n |      An expression that drops fields in :class:`StructType` by name.\n |      This is a no-op if schema doesn't contain field name(s).\n |      \n |      .. versionadded:: 3.1.0\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> from pyspark.sql.functions import col, lit\n |      >>> df = spark.createDataFrame([\n |      ...     Row(a=Row(b=1, c=2, d=3, e=Row(f=4, g=5, h=6)))])\n |      >>> df.withColumn('a', df['a'].dropFields('b')).show()\n |      +-----------------+\n |      |                a|\n |      +-----------------+\n |      |{2, 3, {4, 5, 6}}|\n |      +-----------------+\n |      \n |      >>> df.withColumn('a', df['a'].dropFields('b', 'c')).show()\n |      +--------------+\n |      |             a|\n |      +--------------+\n |      |{3, {4, 5, 6}}|\n |      +--------------+\n |      \n |      This method supports dropping multiple nested fields directly e.g.\n |      \n |      >>> df.withColumn(\"a\", col(\"a\").dropFields(\"e.g\", \"e.h\")).show()\n |      +--------------+\n |      |             a|\n |      +--------------+\n |      |{1, 2, 3, {4}}|\n |      +--------------+\n |      \n |      However, if you are going to add/replace multiple nested fields,\n |      it is preferred to extract out the nested struct before\n |      adding/replacing multiple fields e.g.\n |      \n |      >>> df.select(col(\"a\").withField(\n |      ...     \"e\", col(\"a.e\").dropFields(\"g\", \"h\")).alias(\"a\")\n |      ... ).show()\n |      +--------------+\n |      |             a|\n |      +--------------+\n |      |{1, 2, 3, {4}}|\n |      +--------------+\n |  \n |  endswith = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      String ends with. Returns a boolean :class:`Column` based on a string match.\n |      \n |      Parameters\n |      ----------\n |      other : :class:`Column` or str\n |          string at end of line (do not use a regex `$`)\n |      \n |      Examples\n |      --------\n |      >>> df.filter(df.name.endswith('ice')).collect()\n |      [Row(age=2, name='Alice')]\n |      >>> df.filter(df.name.endswith('ice$')).collect()\n |      []\n |  \n |  eqNullSafe = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      Equality test that is safe for null values.\n |      \n |      .. versionadded:: 2.3.0\n |      \n |      Parameters\n |      ----------\n |      other\n |          a value or :class:`Column`\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df1 = spark.createDataFrame([\n |      ...     Row(id=1, value='foo'),\n |      ...     Row(id=2, value=None)\n |      ... ])\n |      >>> df1.select(\n |      ...     df1['value'] == 'foo',\n |      ...     df1['value'].eqNullSafe('foo'),\n |      ...     df1['value'].eqNullSafe(None)\n |      ... ).show()\n |      +-------------+---------------+----------------+\n |      |(value = foo)|(value <=> foo)|(value <=> NULL)|\n |      +-------------+---------------+----------------+\n |      |         true|           true|           false|\n |      |         null|          false|            true|\n |      +-------------+---------------+----------------+\n |      >>> df2 = spark.createDataFrame([\n |      ...     Row(value = 'bar'),\n |      ...     Row(value = None)\n |      ... ])\n |      >>> df1.join(df2, df1[\"value\"] == df2[\"value\"]).count()\n |      0\n |      >>> df1.join(df2, df1[\"value\"].eqNullSafe(df2[\"value\"])).count()\n |      1\n |      >>> df2 = spark.createDataFrame([\n |      ...     Row(id=1, value=float('NaN')),\n |      ...     Row(id=2, value=42.0),\n |      ...     Row(id=3, value=None)\n |      ... ])\n |      >>> df2.select(\n |      ...     df2['value'].eqNullSafe(None),\n |      ...     df2['value'].eqNullSafe(float('NaN')),\n |      ...     df2['value'].eqNullSafe(42.0)\n |      ... ).show()\n |      +----------------+---------------+----------------+\n |      |(value <=> NULL)|(value <=> NaN)|(value <=> 42.0)|\n |      +----------------+---------------+----------------+\n |      |           false|           true|           false|\n |      |           false|          false|            true|\n |      |            true|          false|           false|\n |      +----------------+---------------+----------------+\n |      \n |      Notes\n |      -----\n |      Unlike Pandas, PySpark doesn't consider NaN values to be NULL. See the\n |      `NaN Semantics <https://spark.apache.org/docs/latest/sql-ref-datatypes.html#nan-semantics>`_\n |      for details.\n |  \n |  getField(self, name: Any) -> 'Column'\n |      An expression that gets a field by name in a :class:`StructType`.\n |      \n |      .. versionadded:: 1.3.0\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([Row(r=Row(a=1, b=\"b\"))])\n |      >>> df.select(df.r.getField(\"b\")).show()\n |      +---+\n |      |r.b|\n |      +---+\n |      |  b|\n |      +---+\n |      >>> df.select(df.r.a).show()\n |      +---+\n |      |r.a|\n |      +---+\n |      |  1|\n |      +---+\n |  \n |  getItem(self, key: Any) -> 'Column'\n |      An expression that gets an item at position ``ordinal`` out of a list,\n |      or gets an item by key out of a dict.\n |      \n |      .. versionadded:: 1.3.0\n |      \n |      Examples\n |      --------\n |      >>> df = spark.createDataFrame([([1, 2], {\"key\": \"value\"})], [\"l\", \"d\"])\n |      >>> df.select(df.l.getItem(0), df.d.getItem(\"key\")).show()\n |      +----+------+\n |      |l[0]|d[key]|\n |      +----+------+\n |      |   1| value|\n |      +----+------+\n |  \n |  ilike = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      SQL ILIKE expression (case insensitive LIKE). Returns a boolean :class:`Column`\n |      based on a case insensitive match.\n |      \n |      .. versionadded:: 3.3.0\n |      \n |      Parameters\n |      ----------\n |      other : str\n |          a SQL LIKE pattern\n |      \n |      See Also\n |      --------\n |      pyspark.sql.Column.rlike\n |      \n |      Examples\n |      --------\n |      >>> df.filter(df.name.ilike('%Ice')).collect()\n |      [Row(age=2, name='Alice')]\n |  \n |  isNotNull = _(self: 'Column') -> 'Column'\n |      True if the current expression is NOT null.\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([Row(name='Tom', height=80), Row(name='Alice', height=None)])\n |      >>> df.filter(df.height.isNotNull()).collect()\n |      [Row(name='Tom', height=80)]\n |  \n |  isNull = _(self: 'Column') -> 'Column'\n |      True if the current expression is null.\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([Row(name='Tom', height=80), Row(name='Alice', height=None)])\n |      >>> df.filter(df.height.isNull()).collect()\n |      [Row(name='Alice', height=None)]\n |  \n |  isin(self, *cols: Any) -> 'Column'\n |      A boolean expression that is evaluated to true if the value of this\n |      expression is contained by the evaluated values of the arguments.\n |      \n |      .. versionadded:: 1.5.0\n |      \n |      Examples\n |      --------\n |      >>> df[df.name.isin(\"Bob\", \"Mike\")].collect()\n |      [Row(age=5, name='Bob')]\n |      >>> df[df.age.isin([1, 2, 3])].collect()\n |      [Row(age=2, name='Alice')]\n |  \n |  like = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      SQL like expression. Returns a boolean :class:`Column` based on a SQL LIKE match.\n |      \n |      Parameters\n |      ----------\n |      other : str\n |          a SQL LIKE pattern\n |      \n |      See Also\n |      --------\n |      pyspark.sql.Column.rlike\n |      \n |      Examples\n |      --------\n |      >>> df.filter(df.name.like('Al%')).collect()\n |      [Row(age=2, name='Alice')]\n |  \n |  name = alias(self, *alias, **kwargs)\n |      :func:`name` is an alias for :func:`alias`.\n |      \n |      .. versionadded:: 2.0\n |  \n |  otherwise(self, value: Any) -> 'Column'\n |      Evaluates a list of conditions and returns one of multiple possible result expressions.\n |      If :func:`Column.otherwise` is not invoked, None is returned for unmatched conditions.\n |      \n |      .. versionadded:: 1.4.0\n |      \n |      Parameters\n |      ----------\n |      value\n |          a literal value, or a :class:`Column` expression.\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import functions as F\n |      >>> df.select(df.name, F.when(df.age > 3, 1).otherwise(0)).show()\n |      +-----+-------------------------------------+\n |      | name|CASE WHEN (age > 3) THEN 1 ELSE 0 END|\n |      +-----+-------------------------------------+\n |      |Alice|                                    0|\n |      |  Bob|                                    1|\n |      +-----+-------------------------------------+\n |      \n |      See Also\n |      --------\n |      pyspark.sql.functions.when\n |  \n |  over(self, window: 'WindowSpec') -> 'Column'\n |      Define a windowing column.\n |      \n |      .. versionadded:: 1.4.0\n |      \n |      Parameters\n |      ----------\n |      window : :class:`WindowSpec`\n |      \n |      Returns\n |      -------\n |      :class:`Column`\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Window\n |      >>> window = Window.partitionBy(\"name\").orderBy(\"age\")                 .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n |      >>> from pyspark.sql.functions import rank, min\n |      >>> from pyspark.sql.functions import desc\n |      >>> df.withColumn(\"rank\", rank().over(window))                 .withColumn(\"min\", min('age').over(window)).sort(desc(\"age\")).show()\n |      +---+-----+----+---+\n |      |age| name|rank|min|\n |      +---+-----+----+---+\n |      |  5|  Bob|   1|  5|\n |      |  2|Alice|   1|  2|\n |      +---+-----+----+---+\n |  \n |  rlike = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      SQL RLIKE expression (LIKE with Regex). Returns a boolean :class:`Column` based on a regex\n |      match.\n |      \n |      Parameters\n |      ----------\n |      other : str\n |          an extended regex expression\n |      \n |      Examples\n |      --------\n |      >>> df.filter(df.name.rlike('ice$')).collect()\n |      [Row(age=2, name='Alice')]\n |  \n |  startswith = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      String starts with. Returns a boolean :class:`Column` based on a string match.\n |      \n |      Parameters\n |      ----------\n |      other : :class:`Column` or str\n |          string at start of line (do not use a regex `^`)\n |      \n |      Examples\n |      --------\n |      >>> df.filter(df.name.startswith('Al')).collect()\n |      [Row(age=2, name='Alice')]\n |      >>> df.filter(df.name.startswith('^Al')).collect()\n |      []\n |  \n |  substr(self, startPos: Union[int, ForwardRef('Column')], length: Union[int, ForwardRef('Column')]) -> 'Column'\n |      Return a :class:`Column` which is a substring of the column.\n |      \n |      .. versionadded:: 1.3.0\n |      \n |      Parameters\n |      ----------\n |      startPos : :class:`Column` or int\n |          start position\n |      length : :class:`Column` or int\n |          length of the substring\n |      \n |      Examples\n |      --------\n |      >>> df.select(df.name.substr(1, 3).alias(\"col\")).collect()\n |      [Row(col='Ali'), Row(col='Bob')]\n |  \n |  when(self, condition: 'Column', value: Any) -> 'Column'\n |      Evaluates a list of conditions and returns one of multiple possible result expressions.\n |      If :func:`Column.otherwise` is not invoked, None is returned for unmatched conditions.\n |      \n |      .. versionadded:: 1.4.0\n |      \n |      Parameters\n |      ----------\n |      condition : :class:`Column`\n |          a boolean :class:`Column` expression.\n |      value\n |          a literal value, or a :class:`Column` expression.\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import functions as F\n |      >>> df.select(df.name, F.when(df.age > 4, 1).when(df.age < 3, -1).otherwise(0)).show()\n |      +-----+------------------------------------------------------------+\n |      | name|CASE WHEN (age > 4) THEN 1 WHEN (age < 3) THEN -1 ELSE 0 END|\n |      +-----+------------------------------------------------------------+\n |      |Alice|                                                          -1|\n |      |  Bob|                                                           1|\n |      +-----+------------------------------------------------------------+\n |      \n |      See Also\n |      --------\n |      pyspark.sql.functions.when\n |  \n |  withField(self, fieldName: str, col: 'Column') -> 'Column'\n |      An expression that adds/replaces a field in :class:`StructType` by name.\n |      \n |      .. versionadded:: 3.1.0\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> from pyspark.sql.functions import lit\n |      >>> df = spark.createDataFrame([Row(a=Row(b=1, c=2))])\n |      >>> df.withColumn('a', df['a'].withField('b', lit(3))).select('a.b').show()\n |      +---+\n |      |  b|\n |      +---+\n |      |  3|\n |      +---+\n |      >>> df.withColumn('a', df['a'].withField('d', lit(4))).select('a.d').show()\n |      +---+\n |      |  d|\n |      +---+\n |      |  4|\n |      +---+\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __hash__ = None\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Help on Column in module pyspark.sql.column object:\n\nclass Column(builtins.object)\n |  Column(jc: py4j.java_gateway.JavaObject) -> None\n |  \n |  A column in a DataFrame.\n |  \n |  :class:`Column` instances can be created by::\n |  \n |      # 1. Select a column out of a DataFrame\n |  \n |      df.colName\n |      df[\"colName\"]\n |  \n |      # 2. Create from an expression\n |      df.colName + 1\n |      1 / df.colName\n |  \n |  .. versionadded:: 1.3.0\n |  \n |  Methods defined here:\n |  \n |  __add__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __and__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __bool__ = __nonzero__(self) -> None\n |  \n |  __contains__(self, item: Any) -> None\n |      # container operators\n |  \n |  __div__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __eq__(self, other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary function\n |  \n |  __ge__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __getattr__(self, item: Any) -> 'Column'\n |  \n |  __getitem__(self, k: Any) -> 'Column'\n |  \n |  __gt__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __init__(self, jc: py4j.java_gateway.JavaObject) -> None\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  __invert__ = _(self: 'Column') -> 'Column'\n |  \n |  __iter__(self) -> None\n |  \n |  __le__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __lt__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __mod__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __mul__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __ne__(self, other: Any) -> 'Column'\n |      binary function\n |  \n |  __neg__ = _(self: 'Column') -> 'Column'\n |  \n |  __nonzero__(self) -> None\n |  \n |  __or__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __pow__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral')]) -> 'Column'\n |      binary function\n |  \n |  __radd__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __rand__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __rdiv__ = _(self: 'Column', other: Union[ForwardRef('LiteralType'), ForwardRef('DecimalLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __repr__(self) -> str\n |      Return repr(self).\n |  \n |  __rmod__ = _(self: 'Column', other: Union[ForwardRef('LiteralType'), ForwardRef('DecimalLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __rmul__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __ror__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __rpow__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral')]) -> 'Column'\n |      binary function\n |  \n |  __rsub__ = _(self: 'Column', other: Union[ForwardRef('LiteralType'), ForwardRef('DecimalLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __rtruediv__ = _(self: 'Column', other: Union[ForwardRef('LiteralType'), ForwardRef('DecimalLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __sub__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  __truediv__ = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      binary operator\n |  \n |  alias(self, *alias: str, **kwargs: Any) -> 'Column'\n |      Returns this column aliased with a new name or names (in the case of expressions that\n |      return more than one column, such as explode).\n |      \n |      .. versionadded:: 1.3.0\n |      \n |      Parameters\n |      ----------\n |      alias : str\n |          desired column names (collects all positional arguments passed)\n |      \n |      Other Parameters\n |      ----------------\n |      metadata: dict\n |          a dict of information to be stored in ``metadata`` attribute of the\n |          corresponding :class:`StructField <pyspark.sql.types.StructField>` (optional, keyword\n |          only argument)\n |      \n |          .. versionchanged:: 2.2.0\n |             Added optional ``metadata`` argument.\n |      \n |      Examples\n |      --------\n |      >>> df.select(df.age.alias(\"age2\")).collect()\n |      [Row(age2=2), Row(age2=5)]\n |      >>> df.select(df.age.alias(\"age3\", metadata={'max': 99})).schema['age3'].metadata['max']\n |      99\n |  \n |  asc = _(self: 'Column') -> 'Column'\n |      Returns a sort expression based on ascending order of the column.\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([('Tom', 80), ('Alice', None)], [\"name\", \"height\"])\n |      >>> df.select(df.name).orderBy(df.name.asc()).collect()\n |      [Row(name='Alice'), Row(name='Tom')]\n |  \n |  asc_nulls_first = _(self: 'Column') -> 'Column'\n |      Returns a sort expression based on ascending order of the column, and null values\n |      return before non-null values.\n |      \n |      .. versionadded:: 2.4.0\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], [\"name\", \"height\"])\n |      >>> df.select(df.name).orderBy(df.name.asc_nulls_first()).collect()\n |      [Row(name=None), Row(name='Alice'), Row(name='Tom')]\n |  \n |  asc_nulls_last = _(self: 'Column') -> 'Column'\n |      Returns a sort expression based on ascending order of the column, and null values\n |      appear after non-null values.\n |      \n |      .. versionadded:: 2.4.0\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], [\"name\", \"height\"])\n |      >>> df.select(df.name).orderBy(df.name.asc_nulls_last()).collect()\n |      [Row(name='Alice'), Row(name='Tom'), Row(name=None)]\n |  \n |  astype = cast(self, dataType)\n |      :func:`astype` is an alias for :func:`cast`.\n |      \n |      .. versionadded:: 1.4\n |  \n |  between(self, lowerBound: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DateTimeLiteral'), ForwardRef('DecimalLiteral')], upperBound: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DateTimeLiteral'), ForwardRef('DecimalLiteral')]) -> 'Column'\n |      True if the current column is between the lower bound and upper bound, inclusive.\n |      \n |      .. versionadded:: 1.3.0\n |      \n |      Examples\n |      --------\n |      >>> df.select(df.name, df.age.between(2, 4)).show()\n |      +-----+---------------------------+\n |      | name|((age >= 2) AND (age <= 4))|\n |      +-----+---------------------------+\n |      |Alice|                       true|\n |      |  Bob|                      false|\n |      +-----+---------------------------+\n |  \n |  bitwiseAND = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      Compute bitwise AND of this expression with another expression.\n |      \n |      Parameters\n |      ----------\n |      other\n |          a value or :class:`Column` to calculate bitwise and(&) with\n |          this :class:`Column`.\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([Row(a=170, b=75)])\n |      >>> df.select(df.a.bitwiseAND(df.b)).collect()\n |      [Row((a & b)=10)]\n |  \n |  bitwiseOR = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      Compute bitwise OR of this expression with another expression.\n |      \n |      Parameters\n |      ----------\n |      other\n |          a value or :class:`Column` to calculate bitwise or(|) with\n |          this :class:`Column`.\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([Row(a=170, b=75)])\n |      >>> df.select(df.a.bitwiseOR(df.b)).collect()\n |      [Row((a | b)=235)]\n |  \n |  bitwiseXOR = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      Compute bitwise XOR of this expression with another expression.\n |      \n |      Parameters\n |      ----------\n |      other\n |          a value or :class:`Column` to calculate bitwise xor(^) with\n |          this :class:`Column`.\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([Row(a=170, b=75)])\n |      >>> df.select(df.a.bitwiseXOR(df.b)).collect()\n |      [Row((a ^ b)=225)]\n |  \n |  cast(self, dataType: Union[pyspark.sql.types.DataType, str]) -> 'Column'\n |      Casts the column into type ``dataType``.\n |      \n |      .. versionadded:: 1.3.0\n |      \n |      Examples\n |      --------\n |      >>> df.select(df.age.cast(\"string\").alias('ages')).collect()\n |      [Row(ages='2'), Row(ages='5')]\n |      >>> df.select(df.age.cast(StringType()).alias('ages')).collect()\n |      [Row(ages='2'), Row(ages='5')]\n |  \n |  contains = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      Contains the other element. Returns a boolean :class:`Column` based on a string match.\n |      \n |      Parameters\n |      ----------\n |      other\n |          string in line. A value as a literal or a :class:`Column`.\n |      \n |      Examples\n |      --------\n |      >>> df.filter(df.name.contains('o')).collect()\n |      [Row(age=5, name='Bob')]\n |  \n |  desc = _(self: 'Column') -> 'Column'\n |      Returns a sort expression based on the descending order of the column.\n |      \n |      .. versionadded:: 2.4.0\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([('Tom', 80), ('Alice', None)], [\"name\", \"height\"])\n |      >>> df.select(df.name).orderBy(df.name.desc()).collect()\n |      [Row(name='Tom'), Row(name='Alice')]\n |  \n |  desc_nulls_first = _(self: 'Column') -> 'Column'\n |      Returns a sort expression based on the descending order of the column, and null values\n |      appear before non-null values.\n |      \n |      .. versionadded:: 2.4.0\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], [\"name\", \"height\"])\n |      >>> df.select(df.name).orderBy(df.name.desc_nulls_first()).collect()\n |      [Row(name=None), Row(name='Tom'), Row(name='Alice')]\n |  \n |  desc_nulls_last = _(self: 'Column') -> 'Column'\n |      Returns a sort expression based on the descending order of the column, and null values\n |      appear after non-null values.\n |      \n |      .. versionadded:: 2.4.0\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], [\"name\", \"height\"])\n |      >>> df.select(df.name).orderBy(df.name.desc_nulls_last()).collect()\n |      [Row(name='Tom'), Row(name='Alice'), Row(name=None)]\n |  \n |  dropFields(self, *fieldNames: str) -> 'Column'\n |      An expression that drops fields in :class:`StructType` by name.\n |      This is a no-op if schema doesn't contain field name(s).\n |      \n |      .. versionadded:: 3.1.0\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> from pyspark.sql.functions import col, lit\n |      >>> df = spark.createDataFrame([\n |      ...     Row(a=Row(b=1, c=2, d=3, e=Row(f=4, g=5, h=6)))])\n |      >>> df.withColumn('a', df['a'].dropFields('b')).show()\n |      +-----------------+\n |      |                a|\n |      +-----------------+\n |      |{2, 3, {4, 5, 6}}|\n |      +-----------------+\n |      \n |      >>> df.withColumn('a', df['a'].dropFields('b', 'c')).show()\n |      +--------------+\n |      |             a|\n |      +--------------+\n |      |{3, {4, 5, 6}}|\n |      +--------------+\n |      \n |      This method supports dropping multiple nested fields directly e.g.\n |      \n |      >>> df.withColumn(\"a\", col(\"a\").dropFields(\"e.g\", \"e.h\")).show()\n |      +--------------+\n |      |             a|\n |      +--------------+\n |      |{1, 2, 3, {4}}|\n |      +--------------+\n |      \n |      However, if you are going to add/replace multiple nested fields,\n |      it is preferred to extract out the nested struct before\n |      adding/replacing multiple fields e.g.\n |      \n |      >>> df.select(col(\"a\").withField(\n |      ...     \"e\", col(\"a.e\").dropFields(\"g\", \"h\")).alias(\"a\")\n |      ... ).show()\n |      +--------------+\n |      |             a|\n |      +--------------+\n |      |{1, 2, 3, {4}}|\n |      +--------------+\n |  \n |  endswith = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      String ends with. Returns a boolean :class:`Column` based on a string match.\n |      \n |      Parameters\n |      ----------\n |      other : :class:`Column` or str\n |          string at end of line (do not use a regex `$`)\n |      \n |      Examples\n |      --------\n |      >>> df.filter(df.name.endswith('ice')).collect()\n |      [Row(age=2, name='Alice')]\n |      >>> df.filter(df.name.endswith('ice$')).collect()\n |      []\n |  \n |  eqNullSafe = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      Equality test that is safe for null values.\n |      \n |      .. versionadded:: 2.3.0\n |      \n |      Parameters\n |      ----------\n |      other\n |          a value or :class:`Column`\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df1 = spark.createDataFrame([\n |      ...     Row(id=1, value='foo'),\n |      ...     Row(id=2, value=None)\n |      ... ])\n |      >>> df1.select(\n |      ...     df1['value'] == 'foo',\n |      ...     df1['value'].eqNullSafe('foo'),\n |      ...     df1['value'].eqNullSafe(None)\n |      ... ).show()\n |      +-------------+---------------+----------------+\n |      |(value = foo)|(value <=> foo)|(value <=> NULL)|\n |      +-------------+---------------+----------------+\n |      |         true|           true|           false|\n |      |         null|          false|            true|\n |      +-------------+---------------+----------------+\n |      >>> df2 = spark.createDataFrame([\n |      ...     Row(value = 'bar'),\n |      ...     Row(value = None)\n |      ... ])\n |      >>> df1.join(df2, df1[\"value\"] == df2[\"value\"]).count()\n |      0\n |      >>> df1.join(df2, df1[\"value\"].eqNullSafe(df2[\"value\"])).count()\n |      1\n |      >>> df2 = spark.createDataFrame([\n |      ...     Row(id=1, value=float('NaN')),\n |      ...     Row(id=2, value=42.0),\n |      ...     Row(id=3, value=None)\n |      ... ])\n |      >>> df2.select(\n |      ...     df2['value'].eqNullSafe(None),\n |      ...     df2['value'].eqNullSafe(float('NaN')),\n |      ...     df2['value'].eqNullSafe(42.0)\n |      ... ).show()\n |      +----------------+---------------+----------------+\n |      |(value <=> NULL)|(value <=> NaN)|(value <=> 42.0)|\n |      +----------------+---------------+----------------+\n |      |           false|           true|           false|\n |      |           false|          false|            true|\n |      |            true|          false|           false|\n |      +----------------+---------------+----------------+\n |      \n |      Notes\n |      -----\n |      Unlike Pandas, PySpark doesn't consider NaN values to be NULL. See the\n |      `NaN Semantics <https://spark.apache.org/docs/latest/sql-ref-datatypes.html#nan-semantics>`_\n |      for details.\n |  \n |  getField(self, name: Any) -> 'Column'\n |      An expression that gets a field by name in a :class:`StructType`.\n |      \n |      .. versionadded:: 1.3.0\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([Row(r=Row(a=1, b=\"b\"))])\n |      >>> df.select(df.r.getField(\"b\")).show()\n |      +---+\n |      |r.b|\n |      +---+\n |      |  b|\n |      +---+\n |      >>> df.select(df.r.a).show()\n |      +---+\n |      |r.a|\n |      +---+\n |      |  1|\n |      +---+\n |  \n |  getItem(self, key: Any) -> 'Column'\n |      An expression that gets an item at position ``ordinal`` out of a list,\n |      or gets an item by key out of a dict.\n |      \n |      .. versionadded:: 1.3.0\n |      \n |      Examples\n |      --------\n |      >>> df = spark.createDataFrame([([1, 2], {\"key\": \"value\"})], [\"l\", \"d\"])\n |      >>> df.select(df.l.getItem(0), df.d.getItem(\"key\")).show()\n |      +----+------+\n |      |l[0]|d[key]|\n |      +----+------+\n |      |   1| value|\n |      +----+------+\n |  \n |  ilike = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      SQL ILIKE expression (case insensitive LIKE). Returns a boolean :class:`Column`\n |      based on a case insensitive match.\n |      \n |      .. versionadded:: 3.3.0\n |      \n |      Parameters\n |      ----------\n |      other : str\n |          a SQL LIKE pattern\n |      \n |      See Also\n |      --------\n |      pyspark.sql.Column.rlike\n |      \n |      Examples\n |      --------\n |      >>> df.filter(df.name.ilike('%Ice')).collect()\n |      [Row(age=2, name='Alice')]\n |  \n |  isNotNull = _(self: 'Column') -> 'Column'\n |      True if the current expression is NOT null.\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([Row(name='Tom', height=80), Row(name='Alice', height=None)])\n |      >>> df.filter(df.height.isNotNull()).collect()\n |      [Row(name='Tom', height=80)]\n |  \n |  isNull = _(self: 'Column') -> 'Column'\n |      True if the current expression is null.\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> df = spark.createDataFrame([Row(name='Tom', height=80), Row(name='Alice', height=None)])\n |      >>> df.filter(df.height.isNull()).collect()\n |      [Row(name='Alice', height=None)]\n |  \n |  isin(self, *cols: Any) -> 'Column'\n |      A boolean expression that is evaluated to true if the value of this\n |      expression is contained by the evaluated values of the arguments.\n |      \n |      .. versionadded:: 1.5.0\n |      \n |      Examples\n |      --------\n |      >>> df[df.name.isin(\"Bob\", \"Mike\")].collect()\n |      [Row(age=5, name='Bob')]\n |      >>> df[df.age.isin([1, 2, 3])].collect()\n |      [Row(age=2, name='Alice')]\n |  \n |  like = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      SQL like expression. Returns a boolean :class:`Column` based on a SQL LIKE match.\n |      \n |      Parameters\n |      ----------\n |      other : str\n |          a SQL LIKE pattern\n |      \n |      See Also\n |      --------\n |      pyspark.sql.Column.rlike\n |      \n |      Examples\n |      --------\n |      >>> df.filter(df.name.like('Al%')).collect()\n |      [Row(age=2, name='Alice')]\n |  \n |  name = alias(self, *alias, **kwargs)\n |      :func:`name` is an alias for :func:`alias`.\n |      \n |      .. versionadded:: 2.0\n |  \n |  otherwise(self, value: Any) -> 'Column'\n |      Evaluates a list of conditions and returns one of multiple possible result expressions.\n |      If :func:`Column.otherwise` is not invoked, None is returned for unmatched conditions.\n |      \n |      .. versionadded:: 1.4.0\n |      \n |      Parameters\n |      ----------\n |      value\n |          a literal value, or a :class:`Column` expression.\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import functions as F\n |      >>> df.select(df.name, F.when(df.age > 3, 1).otherwise(0)).show()\n |      +-----+-------------------------------------+\n |      | name|CASE WHEN (age > 3) THEN 1 ELSE 0 END|\n |      +-----+-------------------------------------+\n |      |Alice|                                    0|\n |      |  Bob|                                    1|\n |      +-----+-------------------------------------+\n |      \n |      See Also\n |      --------\n |      pyspark.sql.functions.when\n |  \n |  over(self, window: 'WindowSpec') -> 'Column'\n |      Define a windowing column.\n |      \n |      .. versionadded:: 1.4.0\n |      \n |      Parameters\n |      ----------\n |      window : :class:`WindowSpec`\n |      \n |      Returns\n |      -------\n |      :class:`Column`\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Window\n |      >>> window = Window.partitionBy(\"name\").orderBy(\"age\")                 .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n |      >>> from pyspark.sql.functions import rank, min\n |      >>> from pyspark.sql.functions import desc\n |      >>> df.withColumn(\"rank\", rank().over(window))                 .withColumn(\"min\", min('age').over(window)).sort(desc(\"age\")).show()\n |      +---+-----+----+---+\n |      |age| name|rank|min|\n |      +---+-----+----+---+\n |      |  5|  Bob|   1|  5|\n |      |  2|Alice|   1|  2|\n |      +---+-----+----+---+\n |  \n |  rlike = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      SQL RLIKE expression (LIKE with Regex). Returns a boolean :class:`Column` based on a regex\n |      match.\n |      \n |      Parameters\n |      ----------\n |      other : str\n |          an extended regex expression\n |      \n |      Examples\n |      --------\n |      >>> df.filter(df.name.rlike('ice$')).collect()\n |      [Row(age=2, name='Alice')]\n |  \n |  startswith = _(self: 'Column', other: Union[ForwardRef('Column'), ForwardRef('LiteralType'), ForwardRef('DecimalLiteral'), ForwardRef('DateTimeLiteral')]) -> 'Column'\n |      String starts with. Returns a boolean :class:`Column` based on a string match.\n |      \n |      Parameters\n |      ----------\n |      other : :class:`Column` or str\n |          string at start of line (do not use a regex `^`)\n |      \n |      Examples\n |      --------\n |      >>> df.filter(df.name.startswith('Al')).collect()\n |      [Row(age=2, name='Alice')]\n |      >>> df.filter(df.name.startswith('^Al')).collect()\n |      []\n |  \n |  substr(self, startPos: Union[int, ForwardRef('Column')], length: Union[int, ForwardRef('Column')]) -> 'Column'\n |      Return a :class:`Column` which is a substring of the column.\n |      \n |      .. versionadded:: 1.3.0\n |      \n |      Parameters\n |      ----------\n |      startPos : :class:`Column` or int\n |          start position\n |      length : :class:`Column` or int\n |          length of the substring\n |      \n |      Examples\n |      --------\n |      >>> df.select(df.name.substr(1, 3).alias(\"col\")).collect()\n |      [Row(col='Ali'), Row(col='Bob')]\n |  \n |  when(self, condition: 'Column', value: Any) -> 'Column'\n |      Evaluates a list of conditions and returns one of multiple possible result expressions.\n |      If :func:`Column.otherwise` is not invoked, None is returned for unmatched conditions.\n |      \n |      .. versionadded:: 1.4.0\n |      \n |      Parameters\n |      ----------\n |      condition : :class:`Column`\n |          a boolean :class:`Column` expression.\n |      value\n |          a literal value, or a :class:`Column` expression.\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import functions as F\n |      >>> df.select(df.name, F.when(df.age > 4, 1).when(df.age < 3, -1).otherwise(0)).show()\n |      +-----+------------------------------------------------------------+\n |      | name|CASE WHEN (age > 4) THEN 1 WHEN (age < 3) THEN -1 ELSE 0 END|\n |      +-----+------------------------------------------------------------+\n |      |Alice|                                                          -1|\n |      |  Bob|                                                           1|\n |      +-----+------------------------------------------------------------+\n |      \n |      See Also\n |      --------\n |      pyspark.sql.functions.when\n |  \n |  withField(self, fieldName: str, col: 'Column') -> 'Column'\n |      An expression that adds/replaces a field in :class:`StructType` by name.\n |      \n |      .. versionadded:: 3.1.0\n |      \n |      Examples\n |      --------\n |      >>> from pyspark.sql import Row\n |      >>> from pyspark.sql.functions import lit\n |      >>> df = spark.createDataFrame([Row(a=Row(b=1, c=2))])\n |      >>> df.withColumn('a', df['a'].withField('b', lit(3))).select('a.b').show()\n |      +---+\n |      |  b|\n |      +---+\n |      |  3|\n |      +---+\n |      >>> df.withColumn('a', df['a'].withField('d', lit(4))).select('a.d').show()\n |      +---+\n |      |  d|\n |      +---+\n |      |  4|\n |      +---+\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __hash__ = None\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import *\nhelp(upper)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a07091dc-fe28-49a3-b85a-9338c82bd30b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Help on function upper in module pyspark.sql.functions:\n\nupper(col: 'ColumnOrName') -> pyspark.sql.column.Column\n    Converts a string expression to upper case.\n    \n    .. versionadded:: 1.5\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Help on function upper in module pyspark.sql.functions:\n\nupper(col: 'ColumnOrName') -> pyspark.sql.column.Column\n    Converts a string expression to upper case.\n    \n    .. versionadded:: 1.5\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["employeeDF.withColumn('nationality' , upper('nationality')).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e0b958ee-38f8-4227-af42-fcd6e0e94483","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+----------+---------+------+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n|          1|     Scott|    Tiger|1000.0| UNITED STATES| +1 123 456 7890|123 45 6789|\n|          2|     Henry|     Ford|1250.0|         INDIA|+91 234 567 8901|456 78 9123|\n|          3|      Nick|   Junior| 750.0|UNITED KINGDOM|+44 111 111 1111|222 33 4444|\n|          4|      Bill|    Gomes|1590.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+----------+---------+------+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n|          1|     Scott|    Tiger|1000.0| UNITED STATES| +1 123 456 7890|123 45 6789|\n|          2|     Henry|     Ford|1250.0|         INDIA|+91 234 567 8901|456 78 9123|\n|          3|      Nick|   Junior| 750.0|UNITED KINGDOM|+44 111 111 1111|222 33 4444|\n|          4|      Bill|    Gomes|1590.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["help(date_format)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1259e6ae-0fa5-4e85-8e6d-ecfcf73f6080","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Help on function date_format in module pyspark.sql.functions:\n\ndate_format(date: 'ColumnOrName', format: str) -> pyspark.sql.column.Column\n    Converts a date/timestamp/string to a value of string in the format specified by the date\n    format given by the second argument.\n    \n    A pattern could be for instance `dd.MM.yyyy` and could return a string like '18.03.1993'. All\n    pattern letters of `datetime pattern`_. can be used.\n    \n    .. _datetime pattern: https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html\n    \n    .. versionadded:: 1.5.0\n    \n    Notes\n    -----\n    Whenever possible, use specialized functions like `year`.\n    \n    Examples\n    --------\n    >>> df = spark.createDataFrame([('2015-04-08',)], ['dt'])\n    >>> df.select(date_format('dt', 'MM/dd/yyy').alias('date')).collect()\n    [Row(date='04/08/2015')]\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Help on function date_format in module pyspark.sql.functions:\n\ndate_format(date: 'ColumnOrName', format: str) -> pyspark.sql.column.Column\n    Converts a date/timestamp/string to a value of string in the format specified by the date\n    format given by the second argument.\n    \n    A pattern could be for instance `dd.MM.yyyy` and could return a string like '18.03.1993'. All\n    pattern letters of `datetime pattern`_. can be used.\n    \n    .. _datetime pattern: https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html\n    \n    .. versionadded:: 1.5.0\n    \n    Notes\n    -----\n    Whenever possible, use specialized functions like `year`.\n    \n    Examples\n    --------\n    >>> df = spark.createDataFrame([('2015-04-08',)], ['dt'])\n    >>> df.select(date_format('dt', 'MM/dd/yyy').alias('date')).collect()\n    [Row(date='04/08/2015')]\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["help(col)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"83bd0498-c7bd-4c41-8e2d-04087c15d156","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Help on function col in module pyspark.sql.functions:\n\ncol(col: str) -> pyspark.sql.column.Column\n    Returns a :class:`~pyspark.sql.Column` based on the given column name.\n    \n    Examples\n    --------\n    >>> col('x')\n    Column<'x'>\n    >>> column('x')\n    Column<'x'>\n    \n    .. versionadded:: 1.3\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Help on function col in module pyspark.sql.functions:\n\ncol(col: str) -> pyspark.sql.column.Column\n    Returns a :class:`~pyspark.sql.Column` based on the given column name.\n    \n    Examples\n    --------\n    >>> col('x')\n    Column<'x'>\n    >>> column('x')\n    Column<'x'>\n    \n    .. versionadded:: 1.3\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.column import Column\nemployeeDF.\\\n    orderBy(upper(employeeDF.first_name).alias('name')).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c9688896-7156-4908-8811-12bb90b106dc","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+----------+---------+------+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n|          4|      Bill|    Gomes|1590.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+----------+---------+------+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n|          4|      Bill|    Gomes|1590.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#'str' object has no attribute 'desc', it has to be converted to column object\n# employeeDF.\\\n#     orderBy('first_name'.desc()).\\\n#     show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7d3a30f1-93cb-4c98-863a-c7837506b864","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["employeeDF.\\\n    orderBy(col('first_name').desc()).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0dac2834-f50c-4b26-a6fd-90275c698868","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+----------+---------+------+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n|          4|      Bill|    Gomes|1590.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+----------+---------+------+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n|          4|      Bill|    Gomes|1590.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["employeeDF.\\\n    orderBy((employeeDF.first_name).desc()).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"539aa708-fb0a-48e3-bca9-00b6398b36e9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+----------+---------+------+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n|          4|      Bill|    Gomes|1590.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+----------+---------+------+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n|          4|      Bill|    Gomes|1590.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.column import Column\nemployeeDF.\\\n    orderBy(upper(employeeDF.first_name).alias('name')).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f744b161-21e1-4d31-9074-b3612e75ac11","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+----------+---------+------+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n|          4|      Bill|    Gomes|1590.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+----------+---------+------+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n|          4|      Bill|    Gomes|1590.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["help(lit)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3cda2f19-16a7-4281-b808-5fd62b2ecaf7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Help on function lit in module pyspark.sql.functions:\n\nlit(col: Any) -> pyspark.sql.column.Column\n    Creates a :class:`~pyspark.sql.Column` of literal value.\n    \n    .. versionadded:: 1.3.0\n    \n    Examples\n    --------\n    >>> df.select(lit(5).alias('height')).withColumn('spark_user', lit(True)).take(1)\n    [Row(height=5, spark_user=True)]\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Help on function lit in module pyspark.sql.functions:\n\nlit(col: Any) -> pyspark.sql.column.Column\n    Creates a :class:`~pyspark.sql.Column` of literal value.\n    \n    .. versionadded:: 1.3.0\n    \n    Examples\n    --------\n    >>> df.select(lit(5).alias('height')).withColumn('spark_user', lit(True)).take(1)\n    [Row(height=5, spark_user=True)]\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#coma is considered as a column name , literals has to be converted using lit function\n# from pyspark.sql.functions import concat\n# employeeDF.\\\n#     select(concat('first_name'), \", \", ('last_name')).\\\n#     show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bfcb20b8-ed86-4feb-9c53-1502f17412a9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["employeeDF.\\\n    select(concat(col(\"first_name\"), \n                  lit(\", \"), \n                  col(\"last_name\")\n                 ).alias(\"full_name\")\n          ).\\\n     show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"08a3f776-bc62-4ceb-b942-f6d1fab6c686","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+------------+\n|   full_name|\n+------------+\n|Scott, Tiger|\n| Henry, Ford|\n|Nick, Junior|\n| Bill, Gomes|\n+------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------------+\n|   full_name|\n+------------+\n|Scott, Tiger|\n| Henry, Ford|\n|Nick, Junior|\n| Bill, Gomes|\n+------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["employeeDF.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"314c5639-2f5d-4c49-bf9a-be7f29b6e17d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+----------+---------+------+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n|          4|      Bill|    Gomes|1590.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+----------+---------+------+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n|          4|      Bill|    Gomes|1590.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["employeeDF.\\\n    select('employee_id',\n          concat(col(\"first_name\"), \n                  lit(\"_ \"), \n                  col(\"last_name\")\n                 ).alias(\"full_name\"),\n           'salary',\n           ((col('salary') * lit(0.2)).alias(\"bonus\"))\n          ).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"57fb44c6-e59d-41b7-8053-59cd0516091a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+------------+------+-----+\n|employee_id|   full_name|salary|bonus|\n+-----------+------------+------+-----+\n|          1|Scott_ Tiger|1000.0|200.0|\n|          2| Henry_ Ford|1250.0|250.0|\n|          3|Nick_ Junior| 750.0|150.0|\n|          4| Bill_ Gomes|1590.0|318.0|\n+-----------+------------+------+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+------------+------+-----+\n|employee_id|   full_name|salary|bonus|\n+-----------+------------+------+-----+\n|          1|Scott_ Tiger|1000.0|200.0|\n|          2| Henry_ Ford|1250.0|250.0|\n|          3|Nick_ Junior| 750.0|150.0|\n|          4| Bill_ Gomes|1590.0|318.0|\n+-----------+------------+------+-----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["employeeDF.\\\n    orderBy((employeeDF.employee_id).desc()).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8db40775-840b-4799-9a59-b4c309846141","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+----------+---------+------+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n|          4|      Bill|    Gomes|1590.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+----------+---------+------+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n|          4|      Bill|    Gomes|1590.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n+-----------+----------+---------+------+--------------+----------------+-----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["employeeDF.\\\n    select('employee_id',\n          concat_ws(\" \" ,\n                    col(\"first_name\"),\n                    col(\"last_name\")\n                   ).alias(\"full_name\"),\n           'salary',\n           (col('salary') * lit(0.2)).alias(\"bonus\")\n          ).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6f6b89f8-cb7f-4a49-a5a6-82de3e648234","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+-----------+------+-----+\n|employee_id|  full_name|salary|bonus|\n+-----------+-----------+------+-----+\n|          1|Scott Tiger|1000.0|200.0|\n|          2| Henry Ford|1250.0|250.0|\n|          3|Nick Junior| 750.0|150.0|\n|          4| Bill Gomes|1590.0|318.0|\n+-----------+-----------+------+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+-----------+------+-----+\n|employee_id|  full_name|salary|bonus|\n+-----------+-----------+------+-----+\n|          1|Scott Tiger|1000.0|200.0|\n|          2| Henry Ford|1250.0|250.0|\n|          3|Nick Junior| 750.0|150.0|\n|          4| Bill Gomes|1590.0|318.0|\n+-----------+-----------+------+-----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["employeeDF.\\\n    select('employee_id',\n           initcap(concat_ws(\" \" ,\n                    col(\"first_name\"),\n                    col(\"last_name\")\n                   )).alias(\"full_name\"),\n            upper('nationality').alias('nationality'),\n           length('phone_number')\n          ).\\\n    show()\n    "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2338b2b6-605b-4c47-b5cb-3ae257968a97","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+-----------+--------------+--------------------+\n|employee_id|  full_name|   nationality|length(phone_number)|\n+-----------+-----------+--------------+--------------------+\n|          1|Scott Tiger| UNITED STATES|                  15|\n|          2| Henry Ford|         INDIA|                  16|\n|          3|Nick Junior|UNITED KINGDOM|                  16|\n|          4| Bill Gomes|     AUSTRALIA|                  16|\n+-----------+-----------+--------------+--------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+-----------+--------------+--------------------+\n|employee_id|  full_name|   nationality|length(phone_number)|\n+-----------+-----------+--------------+--------------------+\n|          1|Scott Tiger| UNITED STATES|                  15|\n|          2| Henry Ford|         INDIA|                  16|\n|          3|Nick Junior|UNITED KINGDOM|                  16|\n|          4| Bill Gomes|     AUSTRALIA|                  16|\n+-----------+-----------+--------------+--------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.select(substring(lit('hello world'),7,5)).show()\ndf.select(substring(lit('hello world'),-5,5)).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c720e437-da91-4c1c-9149-be2c9374135e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------------------------+\n|substring(hello world, 7, 5)|\n+----------------------------+\n|                       world|\n+----------------------------+\n\n+-----------------------------+\n|substring(hello world, -5, 5)|\n+-----------------------------+\n|                        world|\n+-----------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------------------------+\n|substring(hello world, 7, 5)|\n+----------------------------+\n|                       world|\n+----------------------------+\n\n+-----------------------------+\n|substring(hello world, -5, 5)|\n+-----------------------------+\n|                        world|\n+-----------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["employeeDF.\\\n    select('employee_id',\n           'phone_number',\n           'ssn',\n           substring('phone_number',-4,4).alias('last_4')\n          ).\\\n    withColumn('ssn_4' ,substring('ssn',-4,4)).\\\n    withColumn('ssn_4_split' ,split('ssn', ' ')[2]).\\\n    withColumn('area_code' , split('phone_number',' ')[1]).\\\n    show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d450a5cf-9f3e-4fb4-92b0-df46cd8705be","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+----------------+-----------+------+-----+-----------+---------+\n|employee_id|phone_number    |ssn        |last_4|ssn_4|ssn_4_split|area_code|\n+-----------+----------------+-----------+------+-----+-----------+---------+\n|1          |+1 123 456 7890 |123 45 6789|7890  |6789 |6789       |123      |\n|2          |+91 234 567 8901|456 78 9123|8901  |9123 |9123       |234      |\n|3          |+44 111 111 1111|222 33 4444|1111  |4444 |4444       |111      |\n|4          |+61 987 654 3210|789 12 6118|3210  |6118 |6118       |987      |\n+-----------+----------------+-----------+------+-----+-----------+---------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+----------------+-----------+------+-----+-----------+---------+\n|employee_id|phone_number    |ssn        |last_4|ssn_4|ssn_4_split|area_code|\n+-----------+----------------+-----------+------+-----+-----------+---------+\n|1          |+1 123 456 7890 |123 45 6789|7890  |6789 |6789       |123      |\n|2          |+91 234 567 8901|456 78 9123|8901  |9123 |9123       |234      |\n|3          |+44 111 111 1111|222 33 4444|1111  |4444 |4444       |111      |\n|4          |+61 987 654 3210|789 12 6118|3210  |6118 |6118       |987      |\n+-----------+----------------+-----------+------+-----+-----------+---------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["help(explode)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ad7293fd-9cc9-44e3-9229-ee4ed22ec9dd","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Help on function explode in module pyspark.sql.functions:\n\nexplode(col: 'ColumnOrName') -> pyspark.sql.column.Column\n    Returns a new row for each element in the given array or map.\n    Uses the default column name `col` for elements in the array and\n    `key` and `value` for elements in the map unless specified otherwise.\n    \n    .. versionadded:: 1.4.0\n    \n    Examples\n    --------\n    >>> from pyspark.sql import Row\n    >>> eDF = spark.createDataFrame([Row(a=1, intlist=[1,2,3], mapfield={\"a\": \"b\"})])\n    >>> eDF.select(explode(eDF.intlist).alias(\"anInt\")).collect()\n    [Row(anInt=1), Row(anInt=2), Row(anInt=3)]\n    \n    >>> eDF.select(explode(eDF.mapfield).alias(\"key\", \"value\")).show()\n    +---+-----+\n    |key|value|\n    +---+-----+\n    |  a|    b|\n    +---+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Help on function explode in module pyspark.sql.functions:\n\nexplode(col: 'ColumnOrName') -> pyspark.sql.column.Column\n    Returns a new row for each element in the given array or map.\n    Uses the default column name `col` for elements in the array and\n    `key` and `value` for elements in the map unless specified otherwise.\n    \n    .. versionadded:: 1.4.0\n    \n    Examples\n    --------\n    >>> from pyspark.sql import Row\n    >>> eDF = spark.createDataFrame([Row(a=1, intlist=[1,2,3], mapfield={\"a\": \"b\"})])\n    >>> eDF.select(explode(eDF.intlist).alias(\"anInt\")).collect()\n    [Row(anInt=1), Row(anInt=2), Row(anInt=3)]\n    \n    >>> eDF.select(explode(eDF.mapfield).alias(\"key\", \"value\")).show()\n    +---+-----+\n    |key|value|\n    +---+-----+\n    |  a|    b|\n    +---+-----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["help(split)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3cffb992-1c62-4f83-8235-14805fae050b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Help on function split in module pyspark.sql.functions:\n\nsplit(str: 'ColumnOrName', pattern: str, limit: int = -1) -> pyspark.sql.column.Column\n    Splits str around matches of the given pattern.\n    \n    .. versionadded:: 1.5.0\n    \n    Parameters\n    ----------\n    str : :class:`~pyspark.sql.Column` or str\n        a string expression to split\n    pattern : str\n        a string representing a regular expression. The regex string should be\n        a Java regular expression.\n    limit : int, optional\n        an integer which controls the number of times `pattern` is applied.\n    \n        * ``limit > 0``: The resulting array's length will not be more than `limit`, and the\n                         resulting array's last entry will contain all input beyond the last\n                         matched pattern.\n        * ``limit <= 0``: `pattern` will be applied as many times as possible, and the resulting\n                          array can be of any size.\n    \n        .. versionchanged:: 3.0\n           `split` now takes an optional `limit` field. If not provided, default limit value is -1.\n    \n    Examples\n    --------\n    >>> df = spark.createDataFrame([('oneAtwoBthreeC',)], ['s',])\n    >>> df.select(split(df.s, '[ABC]', 2).alias('s')).collect()\n    [Row(s=['one', 'twoBthreeC'])]\n    >>> df.select(split(df.s, '[ABC]', -1).alias('s')).collect()\n    [Row(s=['one', 'two', 'three', ''])]\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Help on function split in module pyspark.sql.functions:\n\nsplit(str: 'ColumnOrName', pattern: str, limit: int = -1) -> pyspark.sql.column.Column\n    Splits str around matches of the given pattern.\n    \n    .. versionadded:: 1.5.0\n    \n    Parameters\n    ----------\n    str : :class:`~pyspark.sql.Column` or str\n        a string expression to split\n    pattern : str\n        a string representing a regular expression. The regex string should be\n        a Java regular expression.\n    limit : int, optional\n        an integer which controls the number of times `pattern` is applied.\n    \n        * ``limit > 0``: The resulting array's length will not be more than `limit`, and the\n                         resulting array's last entry will contain all input beyond the last\n                         matched pattern.\n        * ``limit <= 0``: `pattern` will be applied as many times as possible, and the resulting\n                          array can be of any size.\n    \n        .. versionchanged:: 3.0\n           `split` now takes an optional `limit` field. If not provided, default limit value is -1.\n    \n    Examples\n    --------\n    >>> df = spark.createDataFrame([('oneAtwoBthreeC',)], ['s',])\n    >>> df.select(split(df.s, '[ABC]', 2).alias('s')).collect()\n    [Row(s=['one', 'twoBthreeC'])]\n    >>> df.select(split(df.s, '[ABC]', -1).alias('s')).collect()\n    [Row(s=['one', 'two', 'three', ''])]\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.select(split(lit(\"hello world\"),\" \")).\\\nshow()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cdb4a5ed-583a-41e3-b782-ad99bf6291db","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-------------------------+\n|split(hello world,  , -1)|\n+-------------------------+\n|           [hello, world]|\n+-------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------------------------+\n|split(hello world,  , -1)|\n+-------------------------+\n|           [hello, world]|\n+-------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.select(split(lit(\"hello world\"),\" \")[1]).\\\nshow()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"da44e95d-75b0-4d5b-9082-87e04dab3f04","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------------------------+\n|split(hello world,  , -1)[1]|\n+----------------------------+\n|                       world|\n+----------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------------------------+\n|split(hello world,  , -1)[1]|\n+----------------------------+\n|                       world|\n+----------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.select(explode(split(lit(\"hello world\"),\" \")).alias(\"word\")).\\\nshow()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e7cc19b0-0032-4cfd-b262-4443cf9fff12","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----+\n| word|\n+-----+\n|hello|\n|world|\n+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----+\n| word|\n+-----+\n|hello|\n|world|\n+-----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["emp = [\n(1, \"Scott\", \"Tiger\", 1000.0,\n\"united states\", \"+1 123 456 7890, +1 123 656 7890\", \"123 45 6789\"\n),\n(2, \"Henry\", \"Ford\",  1250.0,\n\"India\", \"+91 234 567 8901, +91 656 567 8901\", \"456 78 9123\"\n),\n(3, \"Nick\", \"Junior\", 750.0,\n\"united KINGDOM\", \"+44 111 111 1111\", \"222 33 4444\"\n),\n(4, \"Bill\", \"Gomes\", 1590.0,\n\"AUSTRALIA\", \"+61 987 654 3210\", \"789 12 6118\"\n)\n]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7d68f8fe-04d0-46ab-8c4c-bcc2272423eb","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["empDF = spark.createDataFrame(emp, \n                                  schema= \"\"\"employee_id INT , first_name STRING, last_name STRING,\n                                  salary FLOAT, nationality STRING, phone_numbers STRING , ssn STRING\"\"\" )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"79c2e892-ecda-4038-9fc4-566c6486e2b2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["empDF.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d8dc336c-962e-4862-9f10-e48b53ceaf0c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+----------+---------+------+--------------+----------------------------------+-----------+\n|employee_id|first_name|last_name|salary|nationality   |phone_numbers                     |ssn        |\n+-----------+----------+---------+------+--------------+----------------------------------+-----------+\n|1          |Scott     |Tiger    |1000.0|united states |+1 123 456 7890, +1 123 656 7890  |123 45 6789|\n|2          |Henry     |Ford     |1250.0|India         |+91 234 567 8901, +91 656 567 8901|456 78 9123|\n|3          |Nick      |Junior   |750.0 |united KINGDOM|+44 111 111 1111                  |222 33 4444|\n|4          |Bill      |Gomes    |1590.0|AUSTRALIA     |+61 987 654 3210                  |789 12 6118|\n+-----------+----------+---------+------+--------------+----------------------------------+-----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+----------+---------+------+--------------+----------------------------------+-----------+\n|employee_id|first_name|last_name|salary|nationality   |phone_numbers                     |ssn        |\n+-----------+----------+---------+------+--------------+----------------------------------+-----------+\n|1          |Scott     |Tiger    |1000.0|united states |+1 123 456 7890, +1 123 656 7890  |123 45 6789|\n|2          |Henry     |Ford     |1250.0|India         |+91 234 567 8901, +91 656 567 8901|456 78 9123|\n|3          |Nick      |Junior   |750.0 |united KINGDOM|+44 111 111 1111                  |222 33 4444|\n|4          |Bill      |Gomes    |1590.0|AUSTRALIA     |+61 987 654 3210                  |789 12 6118|\n+-----------+----------+---------+------+--------------+----------------------------------+-----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import *\nempDF.select('employee_id',explode(split(\"phone_numbers\",\", \")).alias(\"word\")).\\\nshow()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cedb6a7b-6aa2-45f7-aa6d-bd72981d2e6e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+----------------+\n|employee_id|            word|\n+-----------+----------------+\n|          1| +1 123 456 7890|\n|          1| +1 123 656 7890|\n|          2|+91 234 567 8901|\n|          2|+91 656 567 8901|\n|          3|+44 111 111 1111|\n|          4|+61 987 654 3210|\n+-----------+----------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+----------------+\n|employee_id|            word|\n+-----------+----------------+\n|          1| +1 123 456 7890|\n|          1| +1 123 656 7890|\n|          2|+91 234 567 8901|\n|          2|+91 656 567 8901|\n|          3|+44 111 111 1111|\n|          4|+61 987 654 3210|\n+-----------+----------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["emplDF = empDF.\\\n    select('employee_id',\n          concat_ws(' ','first_name',\n                    'last_name').alias(\"full_name\"),\n          'phone_numbers').\\\n    withColumn('phone_number',explode(split('phone_numbers', ',')))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aeb17cf2-2fa2-473b-ab5c-a6e12f55e6e5","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[" emplDF.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0b3593f0-77ab-4982-bc52-732a09cd9936","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+-----------+----------------------------------+-----------------+\n|employee_id|full_name  |phone_numbers                     |phone_number     |\n+-----------+-----------+----------------------------------+-----------------+\n|1          |Scott Tiger|+1 123 456 7890, +1 123 656 7890  |+1 123 456 7890  |\n|1          |Scott Tiger|+1 123 456 7890, +1 123 656 7890  | +1 123 656 7890 |\n|2          |Henry Ford |+91 234 567 8901, +91 656 567 8901|+91 234 567 8901 |\n|2          |Henry Ford |+91 234 567 8901, +91 656 567 8901| +91 656 567 8901|\n|3          |Nick Junior|+44 111 111 1111                  |+44 111 111 1111 |\n|4          |Bill Gomes |+61 987 654 3210                  |+61 987 654 3210 |\n+-----------+-----------+----------------------------------+-----------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+-----------+----------------------------------+-----------------+\n|employee_id|full_name  |phone_numbers                     |phone_number     |\n+-----------+-----------+----------------------------------+-----------------+\n|1          |Scott Tiger|+1 123 456 7890, +1 123 656 7890  |+1 123 456 7890  |\n|1          |Scott Tiger|+1 123 456 7890, +1 123 656 7890  | +1 123 656 7890 |\n|2          |Henry Ford |+91 234 567 8901, +91 656 567 8901|+91 234 567 8901 |\n|2          |Henry Ford |+91 234 567 8901, +91 656 567 8901| +91 656 567 8901|\n|3          |Nick Junior|+44 111 111 1111                  |+44 111 111 1111 |\n|4          |Bill Gomes |+61 987 654 3210                  |+61 987 654 3210 |\n+-----------+-----------+----------------------------------+-----------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["emplDF.\\\n     groupBy('employee_id').\\\n     count().\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2a6fb1bf-800c-4a17-a62b-fd557b50701d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+-----+\n|employee_id|count|\n+-----------+-----+\n|          1|    2|\n|          2|    2|\n|          3|    1|\n|          4|    1|\n+-----------+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+-----+\n|employee_id|count|\n+-----------+-----+\n|          1|    2|\n|          2|    2|\n|          3|    1|\n|          4|    1|\n+-----------+-----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.select(lpad(lit('hello'),10,'*').alias('lpad')).show()\ndf.select(rpad(lit('hello'),10,'*').alias('rpad')).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8e55964e-9912-4215-ae96-b3a5b27c0693","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------+\n|      lpad|\n+----------+\n|*****hello|\n+----------+\n\n+----------+\n|      rpad|\n+----------+\n|hello*****|\n+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+\n|      lpad|\n+----------+\n|*****hello|\n+----------+\n\n+----------+\n|      rpad|\n+----------+\n|hello*****|\n+----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["employeeDF.\\\n    select(concat(lpad('employee_id', 5, '0'),\n                  rpad('first_name', 10, '-'),\n                  rpad('last_name', 10, '-'),\n                  lpad('salary', 10, '0'),\n                  rpad('nationality', 15, '-'),\n                  rpad('phone_number', 17, '-')\n                 ).alias(\"employee\")\n          ).\\\n            show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f834e7ed-fec0-4a0e-9bc9-58c31d4ce6e6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-------------------------------------------------------------------+\n|employee                                                           |\n+-------------------------------------------------------------------+\n|00001Scott-----Tiger-----00001000.0united states--+1 123 456 7890--|\n|00002Henry-----Ford------00001250.0India----------+91 234 567 8901-|\n|00003Nick------Junior----00000750.0united KINGDOM-+44 111 111 1111-|\n|00004Bill------Gomes-----00001590.0AUSTRALIA------+61 987 654 3210-|\n+-------------------------------------------------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------------------------------------------------------------------+\n|employee                                                           |\n+-------------------------------------------------------------------+\n|00001Scott-----Tiger-----00001000.0united states--+1 123 456 7890--|\n|00002Henry-----Ford------00001250.0India----------+91 234 567 8901-|\n|00003Nick------Junior----00000750.0united KINGDOM-+44 111 111 1111-|\n|00004Bill------Gomes-----00001590.0AUSTRALIA------+61 987 654 3210-|\n+-------------------------------------------------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["spark.sql('DESCRIBE FUNCTION trim').show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c08296ae-b188-4473-b9f4-036b7be9f9a4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|function_desc                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|Function: trim                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n|Class: org.apache.spark.sql.catalyst.expressions.StringTrim                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n|Usage: \\n    trim(str) - Removes the leading and trailing space characters from `str`.\\n\\n    trim(BOTH FROM str) - Removes the leading and trailing space characters from `str`.\\n\\n    trim(LEADING FROM str) - Removes the leading space characters from `str`.\\n\\n    trim(TRAILING FROM str) - Removes the trailing space characters from `str`.\\n\\n    trim(trimStr FROM str) - Remove the leading and trailing `trimStr` characters from `str`.\\n\\n    trim(BOTH trimStr FROM str) - Remove the leading and trailing `trimStr` characters from `str`.\\n\\n    trim(LEADING trimStr FROM str) - Remove the leading `trimStr` characters from `str`.\\n\\n    trim(TRAILING trimStr FROM str) - Remove the trailing `trimStr` characters from `str`.\\n  |\n+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|function_desc                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|Function: trim                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n|Class: org.apache.spark.sql.catalyst.expressions.StringTrim                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n|Usage: \\n    trim(str) - Removes the leading and trailing space characters from `str`.\\n\\n    trim(BOTH FROM str) - Removes the leading and trailing space characters from `str`.\\n\\n    trim(LEADING FROM str) - Removes the leading space characters from `str`.\\n\\n    trim(TRAILING FROM str) - Removes the trailing space characters from `str`.\\n\\n    trim(trimStr FROM str) - Remove the leading and trailing `trimStr` characters from `str`.\\n\\n    trim(BOTH trimStr FROM str) - Remove the leading and trailing `trimStr` characters from `str`.\\n\\n    trim(LEADING trimStr FROM str) - Remove the leading `trimStr` characters from `str`.\\n\\n    trim(TRAILING trimStr FROM str) - Remove the trailing `trimStr` characters from `str`.\\n  |\n+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["y=[('  hello world   ', )]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8df848d9-626e-46f2-aa98-21769e9f78ec","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df1=spark.createDataFrame(y, \"dummy STRING\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b8bb4591-6de1-40c3-b8be-1ca877fa4752","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df1.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"96905144-dc37-4207-8c08-223caeb49e1e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------------+\n|           dummy|\n+----------------+\n|  hello world   |\n+----------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------------+\n|           dummy|\n+----------------+\n|  hello world   |\n+----------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df1.\\\n    select(ltrim(\"dummy\").alias(\"ltrim\"),\n           rtrim(\"dummy\").alias(\"rtrim\"),\n           trim(\"dummy\").alias(\"trim\")).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b7d2cd53-5b64-4b6f-9b28-43fea2d46eb8","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+--------------+-------------+-----------+\n|         ltrim|        rtrim|       trim|\n+--------------+-------------+-----------+\n|hello world   |  hello world|hello world|\n+--------------+-------------+-----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------+-------------+-----------+\n|         ltrim|        rtrim|       trim|\n+--------------+-------------+-----------+\n|hello world   |  hello world|hello world|\n+--------------+-------------+-----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["\ndf1.\\\n    withColumn(\"ltrim\", expr(\"trim(LEADING ' ' FROM dummy)\")).\\\n    withColumn(\"rtrim\", expr(\"trim(TRAILING ' ' FROM dummy)\")).\\\n    withColumn(\"trim\", expr(\"trim(BOTH ' ' FROM dummy)\")).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"02701306-0a65-4782-83a6-910bb3bf3415","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------------+--------------+-------------+-----------+\n|           dummy|         ltrim|        rtrim|       trim|\n+----------------+--------------+-------------+-----------+\n|  hello world   |hello world   |  hello world|hello world|\n+----------------+--------------+-------------+-----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------------+--------------+-------------+-----------+\n|           dummy|         ltrim|        rtrim|       trim|\n+----------------+--------------+-------------+-----------+\n|  hello world   |hello world   |  hello world|hello world|\n+----------------+--------------+-------------+-----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.select(to_date(lit(\"20230119\"), \"yyyyMMdd\").alias(\"date\")).show()\ndf.select(to_timestamp(lit(\"20230119 1755\"), \"yyyyMMdd HHmm\").alias(\"timestamp\")).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f920c1c4-917e-49fa-bc4c-35306152291b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------+\n|      date|\n+----------+\n|2023-01-19|\n+----------+\n\n+-------------------+\n|          timestamp|\n+-------------------+\n|2023-01-19 17:55:00|\n+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+\n|      date|\n+----------+\n|2023-01-19|\n+----------+\n\n+-------------------+\n|          timestamp|\n+-------------------+\n|2023-01-19 17:55:00|\n+-------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["help(date_add)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"26416206-d129-4353-944a-be9c503a0913","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Help on function date_add in module pyspark.sql.functions:\n\ndate_add(start: 'ColumnOrName', days: Union[ForwardRef('ColumnOrName'), int]) -> pyspark.sql.column.Column\n    Returns the date that is `days` days after `start`\n    \n    .. versionadded:: 1.5.0\n    \n    Examples\n    --------\n    >>> df = spark.createDataFrame([('2015-04-08', 2,)], ['dt', 'add'])\n    >>> df.select(date_add(df.dt, 1).alias('next_date')).collect()\n    [Row(next_date=datetime.date(2015, 4, 9))]\n    >>> df.select(date_add(df.dt, df.add.cast('integer')).alias('next_date')).collect()\n    [Row(next_date=datetime.date(2015, 4, 10))]\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Help on function date_add in module pyspark.sql.functions:\n\ndate_add(start: 'ColumnOrName', days: Union[ForwardRef('ColumnOrName'), int]) -> pyspark.sql.column.Column\n    Returns the date that is `days` days after `start`\n    \n    .. versionadded:: 1.5.0\n    \n    Examples\n    --------\n    >>> df = spark.createDataFrame([('2015-04-08', 2,)], ['dt', 'add'])\n    >>> df.select(date_add(df.dt, 1).alias('next_date')).collect()\n    [Row(next_date=datetime.date(2015, 4, 9))]\n    >>> df.select(date_add(df.dt, df.add.cast('integer')).alias('next_date')).collect()\n    [Row(next_date=datetime.date(2015, 4, 10))]\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["datetimes = [\n(\"2014-02-28\", \"2014-02-28 10:00:00.123\"),\n(\"2016-02-29\", \"2016-02-29 08:08:08.999\"),\n(\"2017-10-31\", \"2017-12-31 11:59:59.123\"),\n(\"2019-11-30\", \"2019-08-31 00:00:00.000\"),\n(\"2023-01-10\", \"2023-01-10 00:00:00.000\")\n]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"67ee25b4-9ad9-4a7e-8f9d-0db1a84c26a7","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["datetimesDF = spark.createDataFrame (datetimes, schema=\"date STRING, time STRING\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8cd5c1c0-c6d9-4e95-bd00-01fd97e93c7e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["datetimesDF.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1e62c0e2-af87-4644-9c14-ed8c731459c1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------+-----------------------+\n|date      |time                   |\n+----------+-----------------------+\n|2014-02-28|2014-02-28 10:00:00.123|\n|2016-02-29|2016-02-29 08:08:08.999|\n|2017-10-31|2017-12-31 11:59:59.123|\n|2019-11-30|2019-08-31 00:00:00.000|\n|2023-01-10|2023-01-10 00:00:00.000|\n+----------+-----------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+-----------------------+\n|date      |time                   |\n+----------+-----------------------+\n|2014-02-28|2014-02-28 10:00:00.123|\n|2016-02-29|2016-02-29 08:08:08.999|\n|2017-10-31|2017-12-31 11:59:59.123|\n|2019-11-30|2019-08-31 00:00:00.000|\n|2023-01-10|2023-01-10 00:00:00.000|\n+----------+-----------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["datetimesDF.\\\n    withColumn(\"add_time\", date_add(\"time\",10)).\\\n    withColumn(\"add_date\", date_add(\"date\",10)).\\\n    withColumn(\"sub_time\", date_sub(\"time\",10)).\\\n    withColumn(\"sub_date\", date_sub(\"date\",10)).\\\n    withColumn(\"datediff_date\", datediff(current_date(), \"date\")).\\\n    withColumn(\"datediff_time\", datediff(current_timestamp(), \"time\")).\\\n    withColumn(\"months_between_time\", round(months_between(current_timestamp(), \"time\" ), 2)).\\\n    withColumn(\"months_between_date\", months_between(current_date(), \"date\")).\\\n    withColumn(\"add_months_time\", add_months(\"time\" , 2)).\\\n    withColumn(\"add_months_date\", add_months(\"date\" , 2)).\\\n    show(truncate=False)\n               "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7fcc96a7-a26e-42b6-91d2-a867a43bd95c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------+-----------------------+----------+----------+----------+----------+-------------+-------------+-------------------+-------------------+---------------+---------------+\n|date      |time                   |add_time  |add_date  |sub_time  |sub_date  |datediff_date|datediff_time|months_between_time|months_between_date|add_months_time|add_months_date|\n+----------+-----------------------+----------+----------+----------+----------+-------------+-------------+-------------------+-------------------+---------------+---------------+\n|2014-02-28|2014-02-28 10:00:00.123|2014-03-10|2014-03-10|2014-02-18|2014-02-18|3274         |3274         |107.58             |107.58064516       |2014-04-28     |2014-04-28     |\n|2016-02-29|2016-02-29 08:08:08.999|2016-03-10|2016-03-10|2016-02-19|2016-02-19|2543         |2543         |83.55              |83.5483871         |2016-04-29     |2016-04-29     |\n|2017-10-31|2017-12-31 11:59:59.123|2018-01-10|2017-11-10|2017-12-21|2017-10-21|1933         |1872         |61.48              |63.48387097        |2018-02-28     |2017-12-31     |\n|2019-11-30|2019-08-31 00:00:00.000|2019-09-10|2019-12-10|2019-08-21|2019-11-20|1173         |1264         |41.5               |38.51612903        |2019-10-31     |2020-01-30     |\n|2023-01-10|2023-01-10 00:00:00.000|2023-01-20|2023-01-20|2022-12-31|2022-12-31|36           |36           |1.18               |1.16129032         |2023-03-10     |2023-03-10     |\n+----------+-----------------------+----------+----------+----------+----------+-------------+-------------+-------------------+-------------------+---------------+---------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+-----------------------+----------+----------+----------+----------+-------------+-------------+-------------------+-------------------+---------------+---------------+\n|date      |time                   |add_time  |add_date  |sub_time  |sub_date  |datediff_date|datediff_time|months_between_time|months_between_date|add_months_time|add_months_date|\n+----------+-----------------------+----------+----------+----------+----------+-------------+-------------+-------------------+-------------------+---------------+---------------+\n|2014-02-28|2014-02-28 10:00:00.123|2014-03-10|2014-03-10|2014-02-18|2014-02-18|3274         |3274         |107.58             |107.58064516       |2014-04-28     |2014-04-28     |\n|2016-02-29|2016-02-29 08:08:08.999|2016-03-10|2016-03-10|2016-02-19|2016-02-19|2543         |2543         |83.55              |83.5483871         |2016-04-29     |2016-04-29     |\n|2017-10-31|2017-12-31 11:59:59.123|2018-01-10|2017-11-10|2017-12-21|2017-10-21|1933         |1872         |61.48              |63.48387097        |2018-02-28     |2017-12-31     |\n|2019-11-30|2019-08-31 00:00:00.000|2019-09-10|2019-12-10|2019-08-21|2019-11-20|1173         |1264         |41.5               |38.51612903        |2019-10-31     |2020-01-30     |\n|2023-01-10|2023-01-10 00:00:00.000|2023-01-20|2023-01-20|2022-12-31|2022-12-31|36           |36           |1.18               |1.16129032         |2023-03-10     |2023-03-10     |\n+----------+-----------------------+----------+----------+----------+----------+-------------+-------------+-------------------+-------------------+---------------+---------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["datetimesDF.\\\n    withColumn(\"date_trunc_month\", trunc(\"date\", \"MM\")).\\\n    withColumn(\"time_trunc\", trunc(\"time\", \"yyyy\")).\\\n    withColumn(\"date_trunc\", date_trunc(\"dd\", \"date\")).\\\n    withColumn(\"time_trunc\", date_trunc(\"yy\", \"time\")).\\\n    show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fa87db63-c631-4702-b858-7a356889ecdf","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------+-----------------------+----------------+-------------------+-------------------+\n|date      |time                   |date_trunc_month|time_trunc         |date_trunc         |\n+----------+-----------------------+----------------+-------------------+-------------------+\n|2014-02-28|2014-02-28 10:00:00.123|2014-02-01      |2014-01-01 00:00:00|2014-02-28 00:00:00|\n|2016-02-29|2016-02-29 08:08:08.999|2016-02-01      |2016-01-01 00:00:00|2016-02-29 00:00:00|\n|2017-10-31|2017-12-31 11:59:59.123|2017-10-01      |2017-01-01 00:00:00|2017-10-31 00:00:00|\n|2019-11-30|2019-08-31 00:00:00.000|2019-11-01      |2019-01-01 00:00:00|2019-11-30 00:00:00|\n|2023-01-10|2023-01-10 00:00:00.000|2023-01-01      |2023-01-01 00:00:00|2023-01-10 00:00:00|\n+----------+-----------------------+----------------+-------------------+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+-----------------------+----------------+-------------------+-------------------+\n|date      |time                   |date_trunc_month|time_trunc         |date_trunc         |\n+----------+-----------------------+----------------+-------------------+-------------------+\n|2014-02-28|2014-02-28 10:00:00.123|2014-02-01      |2014-01-01 00:00:00|2014-02-28 00:00:00|\n|2016-02-29|2016-02-29 08:08:08.999|2016-02-01      |2016-01-01 00:00:00|2016-02-29 00:00:00|\n|2017-10-31|2017-12-31 11:59:59.123|2017-10-01      |2017-01-01 00:00:00|2017-10-31 00:00:00|\n|2019-11-30|2019-08-31 00:00:00.000|2019-11-01      |2019-01-01 00:00:00|2019-11-30 00:00:00|\n|2023-01-10|2023-01-10 00:00:00.000|2023-01-01      |2023-01-01 00:00:00|2023-01-10 00:00:00|\n+----------+-----------------------+----------------+-------------------+-------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.\\\n    select(current_date().alias(\"current_date\"),\n           current_timestamp().alias(\"current_timestamp\"),\n           year(current_date()).alias(\"year\"),\n           month(current_date()).alias(\"month\"),\n           weekofyear(current_date()).alias(\"weekofyear\"),\n           dayofyear(current_date()).alias(\"dayofyear\"),\n           dayofmonth(current_date()).alias(\"dayofmonth\"),\n           dayofweek(current_date()).alias(\"dayofweek\"),\n           hour(current_timestamp()).alias(\"hour\"),\n           minute(current_timestamp()).alias(\"minute\"),\n           second(current_timestamp()).alias(\"second\")\n          )\\\n    .show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"25a5bdb7-6706-4e2f-93c6-0f0be79439ea","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+------------+-----------------------+----+-----+----------+---------+----------+---------+----+------+------+\n|current_date|current_timestamp      |year|month|weekofyear|dayofyear|dayofmonth|dayofweek|hour|minute|second|\n+------------+-----------------------+----+-----+----------+---------+----------+---------+----+------+------+\n|2023-02-15  |2023-02-15 10:15:24.715|2023|2    |7         |46       |15        |4        |10  |15    |24    |\n+------------+-----------------------+----+-----+----------+---------+----------+---------+----+------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------------+-----------------------+----+-----+----------+---------+----------+---------+----+------+------+\n|current_date|current_timestamp      |year|month|weekofyear|dayofyear|dayofmonth|dayofweek|hour|minute|second|\n+------------+-----------------------+----+-----+----------+---------+----------+---------+----+------+------+\n|2023-02-15  |2023-02-15 10:15:24.715|2023|2    |7         |46       |15        |4        |10  |15    |24    |\n+------------+-----------------------+----+-----+----------+---------+----------+---------+----+------+------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.select(to_date(lit('2021061'), 'yyyyDDD').alias(\"date\"),\n         to_date(lit('02/03/2021'), 'dd/MM/yyy').alias(\"date1\"),\n         to_date(lit('02/Mar/2021'), 'dd/MMM/yyy').alias(\"date2\"),\n         to_date(lit('02/December/2021'), 'dd/MMMM/yyy').alias(\"date3\"),\n         to_timestamp(lit('02/Mar/2021'), 'dd/MMM/yyy').alias(\"date4\"),\n         to_timestamp(lit('02/Mar/2021 18:45:34'), 'dd/MMM/yyy HH:mm:ss').alias(\"date5\")\n         ).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cbb4372f-af06-4a5d-a4b0-fa2e7e719f1a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------+----------+----------+----------+-------------------+-------------------+\n|      date|     date1|     date2|     date3|              date4|              date5|\n+----------+----------+----------+----------+-------------------+-------------------+\n|2021-03-02|2021-03-02|2021-03-02|2021-12-02|2021-03-02 00:00:00|2021-03-02 18:45:34|\n+----------+----------+----------+----------+-------------------+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+----------+----------+----------+-------------------+-------------------+\n|      date|     date1|     date2|     date3|              date4|              date5|\n+----------+----------+----------+----------+-------------------+-------------------+\n|2021-03-02|2021-03-02|2021-03-02|2021-12-02|2021-03-02 00:00:00|2021-03-02 18:45:34|\n+----------+----------+----------+----------+-------------------+-------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["datetimesDF.\\\n    withColumn(\"date_YD\", date_format(\"date\", \"yyyyDDD\").cast(\"int\")).\\\n    withColumn(\"date_YMD\", date_format(\"date\", \"yyyydd\").cast(\"int\")).\\\n    withColumn(\"date_Desc\", date_format(\"date\", \"MMMM EE, yyyy\")).\\\n    withColumn(\"Week_name\", date_format(\"date\", \"EEEE\")).\\\n    withColumn(\"time_YM\", date_format(\"time\", \"yyyyMM\").cast(\"int\")).\\\n    withColumn(\"time_HH\", date_format(\"time\", \"yyyyddHHmm\").cast(\"Long\")).\\\n    withColumn(\"date_ts\", date_format(\"date\", \"yyyyMMddHHmmss\").cast(\"Long\")).\\\n    show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c52f425e-3403-40d6-a295-740b7748040d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------+-----------------------+-------+--------+------------------+---------+-------+----------+--------------+\n|date      |time                   |date_YD|date_YMD|date_Desc         |Week_name|time_YM|time_HH   |date_ts       |\n+----------+-----------------------+-------+--------+------------------+---------+-------+----------+--------------+\n|2014-02-28|2014-02-28 10:00:00.123|2014059|201428  |February Fri, 2014|Friday   |201402 |2014281000|20140228000000|\n|2016-02-29|2016-02-29 08:08:08.999|2016060|201629  |February Mon, 2016|Monday   |201602 |2016290808|20160229000000|\n|2017-10-31|2017-12-31 11:59:59.123|2017304|201731  |October Tue, 2017 |Tuesday  |201712 |2017311159|20171031000000|\n|2019-11-30|2019-08-31 00:00:00.000|2019334|201930  |November Sat, 2019|Saturday |201908 |2019310000|20191130000000|\n|2023-01-10|2023-01-10 00:00:00.000|2023010|202310  |January Tue, 2023 |Tuesday  |202301 |2023100000|20230110000000|\n+----------+-----------------------+-------+--------+------------------+---------+-------+----------+--------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+-----------------------+-------+--------+------------------+---------+-------+----------+--------------+\n|date      |time                   |date_YD|date_YMD|date_Desc         |Week_name|time_YM|time_HH   |date_ts       |\n+----------+-----------------------+-------+--------+------------------+---------+-------+----------+--------------+\n|2014-02-28|2014-02-28 10:00:00.123|2014059|201428  |February Fri, 2014|Friday   |201402 |2014281000|20140228000000|\n|2016-02-29|2016-02-29 08:08:08.999|2016060|201629  |February Mon, 2016|Monday   |201602 |2016290808|20160229000000|\n|2017-10-31|2017-12-31 11:59:59.123|2017304|201731  |October Tue, 2017 |Tuesday  |201712 |2017311159|20171031000000|\n|2019-11-30|2019-08-31 00:00:00.000|2019334|201930  |November Sat, 2019|Saturday |201908 |2019310000|20191130000000|\n|2023-01-10|2023-01-10 00:00:00.000|2023010|202310  |January Tue, 2023 |Tuesday  |202301 |2023100000|20230110000000|\n+----------+-----------------------+-------+--------+------------------+---------+-------+----------+--------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["datetime = [\n    (20140228, \"2014-02-28\", \"2014-02-28 10:00:00\"),\n    (20160321, \"2016-03-21\", \"2016-03-21 08:30:33\"),\n    (20140601, \"2014-06-01\", \"2014-06-01 11:02:24\"),\n    (20161228, \"2018-12-28\", \"2018-12-28 0:00:00\")\n]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"07daf852-6b63-4ecd-bffc-79d67314f3a6","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["dttimeDF = spark.createDataFrame(datetime).toDF(\"dateid\", \"date\", \"time\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"09a244eb-5b68-4bd0-a6bf-16eb5c5378af","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["dttimeDF.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e1f8943d-d60a-4c06-91ec-8b2799fd4dbe","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+--------+----------+-------------------+\n|  dateid|      date|               time|\n+--------+----------+-------------------+\n|20140228|2014-02-28|2014-02-28 10:00:00|\n|20160321|2016-03-21|2016-03-21 08:30:33|\n|20140601|2014-06-01|2014-06-01 11:02:24|\n|20161228|2018-12-28| 2018-12-28 0:00:00|\n+--------+----------+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------+----------+-------------------+\n|  dateid|      date|               time|\n+--------+----------+-------------------+\n|20140228|2014-02-28|2014-02-28 10:00:00|\n|20160321|2016-03-21|2016-03-21 08:30:33|\n|20140601|2014-06-01|2014-06-01 11:02:24|\n|20161228|2018-12-28| 2018-12-28 0:00:00|\n+--------+----------+-------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["dttimeDF.\\\n    withColumn(\"unix_dateid\", unix_timestamp(col(\"dateid\").cast(\"string\"), \"yyyyMMdd\")).\\\n    withColumn(\"unix_date\", unix_timestamp(\"date\", \"yyyy-MM-dd\")).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3be7de20-edf9-4a15-a926-efaecabec655","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+--------+----------+-------------------+-----------+----------+\n|  dateid|      date|               time|unix_dateid| unix_date|\n+--------+----------+-------------------+-----------+----------+\n|20140228|2014-02-28|2014-02-28 10:00:00| 1393545600|1393545600|\n|20160321|2016-03-21|2016-03-21 08:30:33| 1458518400|1458518400|\n|20140601|2014-06-01|2014-06-01 11:02:24| 1401580800|1401580800|\n|20161228|2018-12-28| 2018-12-28 0:00:00| 1482883200|1545955200|\n+--------+----------+-------------------+-----------+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------+----------+-------------------+-----------+----------+\n|  dateid|      date|               time|unix_dateid| unix_date|\n+--------+----------+-------------------+-----------+----------+\n|20140228|2014-02-28|2014-02-28 10:00:00| 1393545600|1393545600|\n|20160321|2016-03-21|2016-03-21 08:30:33| 1458518400|1458518400|\n|20140601|2014-06-01|2014-06-01 11:02:24| 1401580800|1401580800|\n|20161228|2018-12-28| 2018-12-28 0:00:00| 1482883200|1545955200|\n+--------+----------+-------------------+-----------+----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["unixtimes = [\n    (1393545600, ),\n    (1393545600, ),\n    (1401580800, ),\n    (1401580800, )\n]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"380374db-bf1f-4d58-8bdb-158eab3adcb2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["unixtimesDF = spark.createDataFrame(unixtimes).toDF(\"unixtime\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"04c348e5-4f14-49b8-bcad-ea90f41e00d0","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["unixtimesDF.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d02c77b6-adab-4b1d-9897-1faf264a56f6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------+\n|  unixtime|\n+----------+\n|1393545600|\n|1393545600|\n|1401580800|\n|1401580800|\n+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+\n|  unixtime|\n+----------+\n|1393545600|\n|1393545600|\n|1401580800|\n|1401580800|\n+----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["unixtimesDF.\\\n    withColumn(\"date\", from_unixtime(\"unixtime\", format=\"yyyyMMdd\")).\\\n    withColumn(\"time\", from_unixtime(\"unixtime\")).\\\n    withColumn(\"time_stamp\", from_unixtime(\"unixtime\").cast(\"timestamp\")).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0b92f146-69d6-44e0-9e3c-e178ef9fda1e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------+--------+-------------------+-------------------+\n|  unixtime|    date|               time|         time_stamp|\n+----------+--------+-------------------+-------------------+\n|1393545600|20140228|2014-02-28 00:00:00|2014-02-28 00:00:00|\n|1393545600|20140228|2014-02-28 00:00:00|2014-02-28 00:00:00|\n|1401580800|20140601|2014-06-01 00:00:00|2014-06-01 00:00:00|\n|1401580800|20140601|2014-06-01 00:00:00|2014-06-01 00:00:00|\n+----------+--------+-------------------+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+--------+-------------------+-------------------+\n|  unixtime|    date|               time|         time_stamp|\n+----------+--------+-------------------+-------------------+\n|1393545600|20140228|2014-02-28 00:00:00|2014-02-28 00:00:00|\n|1393545600|20140228|2014-02-28 00:00:00|2014-02-28 00:00:00|\n|1401580800|20140601|2014-06-01 00:00:00|2014-06-01 00:00:00|\n|1401580800|20140601|2014-06-01 00:00:00|2014-06-01 00:00:00|\n+----------+--------+-------------------+-------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["sample = [\n(1, \"Scott\", None, 1000.0, 10,\n\"united states\", \"+1 123 456 7890\", \"123 45 6789\"\n),\n(2, \"Henry\", \"Ford\",  1250.0, None,\n\"India\", \"+91 234 567 8901\", \"456 78 9123\"\n),\n(3, \"Nick\",None, 750.0, '',\n\"united KINGDOM\", \"+44 111 111 1111\", \"222 33 4444\"\n),\n(4, \"Bill\", \"Gomes\", 1590.0,10,\n\"AUSTRALIA\", \"+61 987 654 3210\", \"789 12 6118\"\n)\n]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6066e2a1-630d-4de1-b7e4-d568289d2cde","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["sampleDF = spark.createDataFrame(sample, \n                                  schema= \"\"\"employee_id INT , first_name STRING, last_name STRING,\n                                  salary FLOAT, bonus STRING, nationality STRING, phone_number STRING , ssn STRING\"\"\" )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ca222475-bb1f-472a-9f5f-903f10a17f5b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["sampleDF.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2c561db4-f04e-4374-bf7c-f96f00339843","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n|          1|     Scott|     null|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123|\n|          3|      Nick|     null| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|\n|          4|      Bill|    Gomes|1590.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n|          1|     Scott|     null|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123|\n|          3|      Nick|     null| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|\n|          4|      Bill|    Gomes|1590.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import coalesce , lit, col\nsampleDF.\\\n    withColumn('bonus1', coalesce('bonus', lit(0))).\\\n    withColumn('bonus2', col('bonus1').cast(\"int\")).\\\n     withColumn('bonus3', coalesce(col('bonus').cast(\"int\"), lit(0))).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0ff95046-a691-45e6-a02a-03517d40bde6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+------+------+\n|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|bonus1|bonus2|bonus3|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+------+------+\n|          1|     Scott|     null|1000.0|   10| united states| +1 123 456 7890|123 45 6789|    10|    10|    10|\n|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123|     0|     0|     0|\n|          3|      Nick|     null| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|      |  null|     0|\n|          4|      Bill|    Gomes|1590.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|    10|    10|    10|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+------+------+\n|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|bonus1|bonus2|bonus3|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+------+------+\n|          1|     Scott|     null|1000.0|   10| united states| +1 123 456 7890|123 45 6789|    10|    10|    10|\n|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123|     0|     0|     0|\n|          3|      Nick|     null| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|      |  null|     0|\n|          4|      Bill|    Gomes|1590.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|    10|    10|    10|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+------+------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import coalesce , lit, col, expr\nsampleDF.\\\n     withColumn('bonus1',expr(\"nvl(bonus,0)\")).\\\n     withColumn('bonus2',expr(\"nullif(bonus,'')\")).\\\n     withColumn('bonus3',expr(\"nvl(nullif(bonus,''),0)\")).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a0f37b1f-4894-4abe-bbc8-8b7d741a3de5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+------+------+\n|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|bonus1|bonus2|bonus3|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+------+------+\n|          1|     Scott|     null|1000.0|   10| united states| +1 123 456 7890|123 45 6789|    10|    10|    10|\n|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123|     0|  null|     0|\n|          3|      Nick|     null| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|      |  null|     0|\n|          4|      Bill|    Gomes|1590.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|    10|    10|    10|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+------+------+\n|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|bonus1|bonus2|bonus3|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+------+------+\n|          1|     Scott|     null|1000.0|   10| united states| +1 123 456 7890|123 45 6789|    10|    10|    10|\n|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123|     0|  null|     0|\n|          3|      Nick|     null| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|      |  null|     0|\n|          4|      Bill|    Gomes|1590.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|    10|    10|    10|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+------+------+------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["sampleDF.\\\n    withColumn('payment', col('salary')+(col('salary')*coalesce(col('bonus').cast('int'),lit(0)/100))).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"983ab3ed-135f-4d6c-b48f-e8a1dd1266d0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+----------+---------+------+-----+--------------+----------------+-----------+-------+\n|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|payment|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+-------+\n|          1|     Scott|     null|1000.0|   10| united states| +1 123 456 7890|123 45 6789|11000.0|\n|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123| 1250.0|\n|          3|      Nick|     null| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|  750.0|\n|          4|      Bill|    Gomes|1590.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|17490.0|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+-------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+----------+---------+------+-----+--------------+----------------+-----------+-------+\n|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|payment|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+-------+\n|          1|     Scott|     null|1000.0|   10| united states| +1 123 456 7890|123 45 6789|11000.0|\n|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123| 1250.0|\n|          3|      Nick|     null| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|  750.0|\n|          4|      Bill|    Gomes|1590.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|17490.0|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+-------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["sampleDF.fillna(0.0).fillna('na','last_name').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"28f11fba-0206-4150-b74d-3a5b13de99bb","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n|          1|     Scott|       na|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123|\n|          3|      Nick|       na| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|\n|          4|      Bill|    Gomes|1590.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n|          1|     Scott|       na|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123|\n|          3|      Nick|       na| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|\n|          4|      Bill|    Gomes|1590.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["sampleDF.\\\n    withColumn('bonus',\n              expr(\"\"\"\n              CASE WHEN bonus IS NULL OR bonus = '' THEN 0\n              ELSE bonus\n              end\n              \"\"\")).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"981c27d6-c553-4838-bc11-5079076472b2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n|          1|     Scott|     null|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n|          2|     Henry|     Ford|1250.0|    0|         India|+91 234 567 8901|456 78 9123|\n|          3|      Nick|     null| 750.0|    0|united KINGDOM|+44 111 111 1111|222 33 4444|\n|          4|      Bill|    Gomes|1590.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n|          1|     Scott|     null|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n|          2|     Henry|     Ford|1250.0|    0|         India|+91 234 567 8901|456 78 9123|\n|          3|      Nick|     null| 750.0|    0|united KINGDOM|+44 111 111 1111|222 33 4444|\n|          4|      Bill|    Gomes|1590.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import when\nsampleDF.\\\n    withColumn(\"category\",\n              when ((col('salary')>0) & (col('salary')<=1000 ), '1evel-1').\n              when ((col('salary')>1000) & (col('salary')<=1500 ), '1evel-2').\n              when ((col('salary')>1500) & (col('salary')<=2000 ), '1evel-3').\n              otherwise('level-0')\n              ).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a94721be-2da3-47a5-8e45-767bdf93a334","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+----------+---------+------+-----+--------------+----------------+-----------+--------+\n|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|category|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+--------+\n|          1|     Scott|     null|1000.0|   10| united states| +1 123 456 7890|123 45 6789| 1evel-1|\n|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123| 1evel-2|\n|          3|      Nick|     null| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444| 1evel-1|\n|          4|      Bill|    Gomes|1590.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118| 1evel-3|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+--------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+----------+---------+------+-----+--------------+----------------+-----------+--------+\n|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|category|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+--------+\n|          1|     Scott|     null|1000.0|   10| united states| +1 123 456 7890|123 45 6789| 1evel-1|\n|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123| 1evel-2|\n|          3|      Nick|     null| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444| 1evel-1|\n|          4|      Bill|    Gomes|1590.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118| 1evel-3|\n+-----------+----------+---------+------+-----+--------------+----------------+-----------+--------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import Row"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"90d76161-8cfd-498e-a836-1a57e3252226","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["\nimport datetime\nusers = [\n    {\n        \"id\": 1,\n        \"first_name\": \"Corrie\",\n        \"last_name\": \"Van den Oord\",\n        \"email\": \"cvandenoorde@etsy.com\",\n        \"gender\": \"male\",\n        \"current_city\": \"Dallas\",\n        \"phone_numbers\": Row (mobile=\"+1 234 567 8901\", home=\"+1 234 567 8911\"),\n        \"courses\": [1, 2],\n        \"is_customer\": True,\n        \"amount_paid\": 1000.55,\n        \"customer_from\": datetime.date (2021, 1, 15),\n        \"last_updated_ts\": datetime.datetime (2021, 2, 10, 1, 15, 0)\n    },\n    {\n        \"id\": 2,\n        \"first_name\": \"Nikolaus\",\n        \"last_name\": \"Brewitt\",\n        \"email\": \"nbrewittl@dailymail.co.uk\",\n        \"gender\": \"male\",\n        \"current_city\": \"Dallas\",\n        \"phone_numbers\": Row (mobile=\"+1 234 767 8901\", home=\"+1 234 767 8911\"),\n        \"courses\": [3],\n        \"is_customer\": True,\n        \"amount_paid\": 900.0,\n        \"customer_from\": datetime.date (2021, 2, 14),\n        \"last_updated_ts\": datetime.datetime (2021, 2, 10, 1, 15, 0)\n    },\n    {\n        \"id\": 3,\n        \"first_name\": \"Orelie\",\n        \"last_name\": \"penney\",\n        \"email\": \"penney2@dailymail.co.uk\",\n        \"gender\": \"female\",\n        \"current_city\": \"\",\n        \"phone_numbers\": Row (mobile=\"+1 234 767 8901\", home=\"+1 234 767 8911\"),\n        \"courses\": [2,4],\n        \"is_customer\": True,\n        \"amount_paid\": 890.0,\n        \"customer_from\": datetime.date (2021, 1, 21),\n        \"last_updated_ts\": datetime.datetime (2021, 3, 10, 1, 15, 0)\n    },\n    {\n        \"id\": 4,\n        \"first_name\": \"Ashby\",\n        \"last_name\": \"MAddocks\",\n        \"email\": \"maddocks@home.plk\",\n        \"gender\": \"male\",\n        \"current_city\": \"San Frnasisco\",\n        \"phone_numbers\": Row (mobile=None, home=None),\n        \"courses\": [],\n        \"is_customer\": False,\n        \"amount_paid\": None,\n        \"customer_from\": None,\n        \"last_updated_ts\": datetime.datetime (2021, 4, 10, 17, 45, 30)\n    },\n    {\n        \"id\": 5,\n        \"first_name\": \"Kurt\",\n        \"last_name\": \"Rome\",\n        \"email\": \"krome4@shutterfly.com\",\n        \"gender\": \"female\",\n        \"current_city\": None,\n        \"phone_numbers\": Row (mobile=\"+1 817 934 7142\", home=None),\n        \"courses\": [],\n        \"is_customer\": False,\n        \"amount_paid\": None,\n        \"customer_from\": None,\n        \"last_updated_ts\": datetime.datetime (2021, 4, 2, 0, 55, 18)\n    }\n]\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f60d5e57-0b3b-45ab-b471-9172982d3f73","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0bd0057e-1a34-4357-acef-c4094b63852f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":{"text/plain":"","application/vnd.databricks.v1+bamboolib_hint":"{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}"},"removedWidgets":[],"addedWidgets":{},"executionCount":null,"metadata":{"kernelSessionId":"81aa45dc-e596abfc5f1a7f204f685abb"},"type":"mimeBundle","arguments":{}}},"output_type":"display_data","data":{"text/plain":"","application/vnd.databricks.v1+bamboolib_hint":"{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}"}}],"execution_count":0},{"cell_type":"code","source":["spark.conf.set('spark.sql.execurion.arrow.pyspark.enabled',False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"03b87342-9f0a-4425-81fd-957772da4241","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["users_df = spark.createDataFrame(pd.DataFrame(users))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4621bd43-0959-4373-bd09-04bdebf83ddc","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["users_df.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"729622d1-74e6-409e-9faa-3d2063835a8d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+---+----------+------------+-------------------------+------+-------------+----------------------------------+-------+-----------+-----------+-------------+-------------------+\n|id |first_name|last_name   |email                    |gender|current_city |phone_numbers                     |courses|is_customer|amount_paid|customer_from|last_updated_ts    |\n+---+----------+------------+-------------------------+------+-------------+----------------------------------+-------+-----------+-----------+-------------+-------------------+\n|1  |Corrie    |Van den Oord|cvandenoorde@etsy.com    |male  |Dallas       |[+1 234 567 8901, +1 234 567 8911]|[1, 2] |true       |1000.55    |2021-01-15   |2021-02-10 01:15:00|\n|2  |Nikolaus  |Brewitt     |nbrewittl@dailymail.co.uk|male  |Dallas       |[+1 234 767 8901, +1 234 767 8911]|[3]    |true       |900.0      |2021-02-14   |2021-02-10 01:15:00|\n|3  |Orelie    |penney      |penney2@dailymail.co.uk  |female|             |[+1 234 767 8901, +1 234 767 8911]|[2, 4] |true       |890.0      |2021-01-21   |2021-03-10 01:15:00|\n|4  |Ashby     |MAddocks    |maddocks@home.plk        |male  |San Frnasisco|[null, null]                      |[]     |false      |null       |null         |2021-04-10 17:45:30|\n|5  |Kurt      |Rome        |krome4@shutterfly.com    |female|null         |[+1 817 934 7142, null]           |[]     |false      |null       |null         |2021-04-02 00:55:18|\n+---+----------+------------+-------------------------+------+-------------+----------------------------------+-------+-----------+-----------+-------------+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+----------+------------+-------------------------+------+-------------+----------------------------------+-------+-----------+-----------+-------------+-------------------+\n|id |first_name|last_name   |email                    |gender|current_city |phone_numbers                     |courses|is_customer|amount_paid|customer_from|last_updated_ts    |\n+---+----------+------------+-------------------------+------+-------------+----------------------------------+-------+-----------+-----------+-------------+-------------------+\n|1  |Corrie    |Van den Oord|cvandenoorde@etsy.com    |male  |Dallas       |[+1 234 567 8901, +1 234 567 8911]|[1, 2] |true       |1000.55    |2021-01-15   |2021-02-10 01:15:00|\n|2  |Nikolaus  |Brewitt     |nbrewittl@dailymail.co.uk|male  |Dallas       |[+1 234 767 8901, +1 234 767 8911]|[3]    |true       |900.0      |2021-02-14   |2021-02-10 01:15:00|\n|3  |Orelie    |penney      |penney2@dailymail.co.uk  |female|             |[+1 234 767 8901, +1 234 767 8911]|[2, 4] |true       |890.0      |2021-01-21   |2021-03-10 01:15:00|\n|4  |Ashby     |MAddocks    |maddocks@home.plk        |male  |San Frnasisco|[null, null]                      |[]     |false      |null       |null         |2021-04-10 17:45:30|\n|5  |Kurt      |Rome        |krome4@shutterfly.com    |female|null         |[+1 817 934 7142, null]           |[]     |false      |null       |null         |2021-04-02 00:55:18|\n+---+----------+------------+-------------------------+------+-------------+----------------------------------+-------+-----------+-----------+-------------+-------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["users_df.createOrReplaceTempView('users')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"554510e8-8fc5-4348-9e4f-20050137c4e2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["users_df.where('id<=2').show()\nusers_df.filter(users_df['id']==3).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b50b07ba-e119-4ae2-b4e4-36853f07ea28","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+---+----------+------------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender|current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|      Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|      Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n+---+----------+------------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n+---+----------+---------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|last_name|               email|gender|current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+---------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  3|    Orelie|   penney|penney2@dailymail...|female|            |[+1 234 767 8901,...| [2, 4]|       true|      890.0|   2021-01-21|2021-03-10 01:15:00|\n+---+----------+---------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+----------+------------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender|current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|      Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|      Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n+---+----------+------------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n+---+----------+---------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|last_name|               email|gender|current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+---------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  3|    Orelie|   penney|penney2@dailymail...|female|            |[+1 234 767 8901,...| [2, 4]|       true|      890.0|   2021-01-21|2021-03-10 01:15:00|\n+---+----------+---------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["spark.sql(\"\"\"\n            SELECT *\n            FROM\n            users\n            where id<=2\n            \"\"\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0a064f70-642f-4d67-a331-4e6ec6a90ccd","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+---+----------+------------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender|current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|      Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|      Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n+---+----------+------------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+----------+------------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender|current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|      Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|      Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n+---+----------+------------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["users_df.filter(col('is_customer')==False).show()\nusers_df.filter(col('is_customer')=='false').show()\nusers_df.filter('is_customer=false').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ce1d6b8c-571d-4a25-879a-71a760c943e5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+---+----------+---------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+---------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  4|     Ashby| MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n|  5|      Kurt|     Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n+---+----------+---------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n+---+----------+---------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+---------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  4|     Ashby| MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n|  5|      Kurt|     Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n+---+----------+---------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n+---+----------+---------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+---------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  4|     Ashby| MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n|  5|      Kurt|     Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n+---+----------+---------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+----------+---------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+---------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  4|     Ashby| MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n|  5|      Kurt|     Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n+---+----------+---------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n+---+----------+---------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+---------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  4|     Ashby| MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n|  5|      Kurt|     Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n+---+----------+---------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n+---+----------+---------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+---------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  4|     Ashby| MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n|  5|      Kurt|     Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n+---+----------+---------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["spark.sql(\"\"\"\n            SELECT *\n            FROM users\n            WHERE amount_paid>=900\"\"\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fb5ada9c-3b2b-451a-b86c-58d65321b237","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+---+----------+------------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender|current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|      Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|      Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n+---+----------+------------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+----------+------------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender|current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|      Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|      Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n+---+----------+------------+--------------------+------+------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import isnan\nusers_df.select('amount_paid', isnan('amount_paid')).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6d8af9a9-e165-4390-8fc4-f4400a8afdfd","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-----------+------------------+\n|amount_paid|isnan(amount_paid)|\n+-----------+------------------+\n|    1000.55|             false|\n|      900.0|             false|\n|      890.0|             false|\n|       null|             false|\n|       null|             false|\n+-----------+------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+------------------+\n|amount_paid|isnan(amount_paid)|\n+-----------+------------------+\n|    1000.55|             false|\n|      900.0|             false|\n|      890.0|             false|\n|       null|             false|\n|       null|             false|\n+-----------+------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["users_df.\\\n    select('id',\n          'first_name',\n          'current_city').\\\n    where(\"current_city!='' AND current_city='Dallas'\").\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"73f84558-ba3e-4193-b36c-6363678ecc07","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+---+----------+------------+\n| id|first_name|current_city|\n+---+----------+------------+\n|  1|    Corrie|      Dallas|\n|  2|  Nikolaus|      Dallas|\n+---+----------+------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+----------+------------+\n| id|first_name|current_city|\n+---+----------+------------+\n|  1|    Corrie|      Dallas|\n|  2|  Nikolaus|      Dallas|\n+---+----------+------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["users_df.\\\n    select ('id','first_name').\\\n    filter(col('last_updated_ts').between('2021-02-10 00:00:00','2021-03-15 23:59:59')).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"51cda11e-e7f4-4e8a-b924-4281ff630041","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+---+----------+\n| id|first_name|\n+---+----------+\n|  1|    Corrie|\n|  2|  Nikolaus|\n|  3|    Orelie|\n+---+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+----------+\n| id|first_name|\n+---+----------+\n|  1|    Corrie|\n|  2|  Nikolaus|\n|  3|    Orelie|\n+---+----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["users_df.\\\n    select ('id','first_name').\\\n    filter(\"last_updated_ts BETWEEN '2021-02-10 00:00:00' AND '2021-03-15 23:59:59'\").\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6fce89b5-6e67-4196-ae11-54ad4359a3a7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+---+----------+\n| id|first_name|\n+---+----------+\n|  1|    Corrie|\n|  2|  Nikolaus|\n|  3|    Orelie|\n+---+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+----------+\n| id|first_name|\n+---+----------+\n|  1|    Corrie|\n|  2|  Nikolaus|\n|  3|    Orelie|\n+---+----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# sorting in ascending order\nusers_df.sort('first_name').show()\nusers_df.sort(users_df.first_name).show()\nusers_df.sort(users_df['first_name']).show()\nusers_df.sort(col('first_name')).show()\nusers_df.sort(asc('first_name')).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ddff2f76-86e6-4f79-acd3-3735299b8ccc","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  4|     Ashby|    MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|       Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  5|      Kurt|        Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|       Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n|  3|    Orelie|      penney|penney2@dailymail...|female|             |[+1 234 767 8901,...| [2, 4]|       true|      890.0|   2021-01-21|2021-03-10 01:15:00|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  4|     Ashby|    MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|       Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  5|      Kurt|        Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|       Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n|  3|    Orelie|      penney|penney2@dailymail...|female|             |[+1 234 767 8901,...| [2, 4]|       true|      890.0|   2021-01-21|2021-03-10 01:15:00|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  4|     Ashby|    MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|       Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  5|      Kurt|        Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|       Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n|  3|    Orelie|      penney|penney2@dailymail...|female|             |[+1 234 767 8901,...| [2, 4]|       true|      890.0|   2021-01-21|2021-03-10 01:15:00|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  4|     Ashby|    MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|       Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  5|      Kurt|        Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|       Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n|  3|    Orelie|      penney|penney2@dailymail...|female|             |[+1 234 767 8901,...| [2, 4]|       true|      890.0|   2021-01-21|2021-03-10 01:15:00|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  4|     Ashby|    MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|       Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  5|      Kurt|        Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|       Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n|  3|    Orelie|      penney|penney2@dailymail...|female|             |[+1 234 767 8901,...| [2, 4]|       true|      890.0|   2021-01-21|2021-03-10 01:15:00|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  4|     Ashby|    MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|       Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  5|      Kurt|        Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|       Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n|  3|    Orelie|      penney|penney2@dailymail...|female|             |[+1 234 767 8901,...| [2, 4]|       true|      890.0|   2021-01-21|2021-03-10 01:15:00|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  4|     Ashby|    MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|       Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  5|      Kurt|        Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|       Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n|  3|    Orelie|      penney|penney2@dailymail...|female|             |[+1 234 767 8901,...| [2, 4]|       true|      890.0|   2021-01-21|2021-03-10 01:15:00|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  4|     Ashby|    MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|       Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  5|      Kurt|        Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|       Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n|  3|    Orelie|      penney|penney2@dailymail...|female|             |[+1 234 767 8901,...| [2, 4]|       true|      890.0|   2021-01-21|2021-03-10 01:15:00|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  4|     Ashby|    MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|       Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  5|      Kurt|        Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|       Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n|  3|    Orelie|      penney|penney2@dailymail...|female|             |[+1 234 767 8901,...| [2, 4]|       true|      890.0|   2021-01-21|2021-03-10 01:15:00|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  4|     Ashby|    MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|       Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  5|      Kurt|        Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|       Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n|  3|    Orelie|      penney|penney2@dailymail...|female|             |[+1 234 767 8901,...| [2, 4]|       true|      890.0|   2021-01-21|2021-03-10 01:15:00|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# sorting data based on size of list\nfrom pyspark.sql.functions import size\nusers_df.\\\n    select('id','courses').\\\n    withColumn('courses_count',size('courses')).\\\n    sort(size('courses')).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a2e393ac-c95c-44f5-bf02-54b3703f2a0d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+---+-------+-------------+\n| id|courses|courses_count|\n+---+-------+-------------+\n|  4|     []|            0|\n|  5|     []|            0|\n|  2|    [3]|            1|\n|  1| [1, 2]|            2|\n|  3| [2, 4]|            2|\n+---+-------+-------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+-------+-------------+\n| id|courses|courses_count|\n+---+-------+-------------+\n|  4|     []|            0|\n|  5|     []|            0|\n|  2|    [3]|            1|\n|  1| [1, 2]|            2|\n|  3| [2, 4]|            2|\n+---+-------+-------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#sorting in descending order\nusers_df.sort('first_name', ascending=False).show()\nusers_df.sort(col('first_name').desc()).show()\nusers_df.sort(desc('first_name')).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"82372e41-51fc-4ce3-9856-4540881ff423","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  3|    Orelie|      penney|penney2@dailymail...|female|             |[+1 234 767 8901,...| [2, 4]|       true|      890.0|   2021-01-21|2021-03-10 01:15:00|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|       Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n|  5|      Kurt|        Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|       Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  4|     Ashby|    MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  3|    Orelie|      penney|penney2@dailymail...|female|             |[+1 234 767 8901,...| [2, 4]|       true|      890.0|   2021-01-21|2021-03-10 01:15:00|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|       Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n|  5|      Kurt|        Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|       Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  4|     Ashby|    MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  3|    Orelie|      penney|penney2@dailymail...|female|             |[+1 234 767 8901,...| [2, 4]|       true|      890.0|   2021-01-21|2021-03-10 01:15:00|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|       Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n|  5|      Kurt|        Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|       Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  4|     Ashby|    MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  3|    Orelie|      penney|penney2@dailymail...|female|             |[+1 234 767 8901,...| [2, 4]|       true|      890.0|   2021-01-21|2021-03-10 01:15:00|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|       Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n|  5|      Kurt|        Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|       Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  4|     Ashby|    MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  3|    Orelie|      penney|penney2@dailymail...|female|             |[+1 234 767 8901,...| [2, 4]|       true|      890.0|   2021-01-21|2021-03-10 01:15:00|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|       Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n|  5|      Kurt|        Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|       Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  4|     Ashby|    MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  3|    Orelie|      penney|penney2@dailymail...|female|             |[+1 234 767 8901,...| [2, 4]|       true|      890.0|   2021-01-21|2021-03-10 01:15:00|\n|  2|  Nikolaus|     Brewitt|nbrewittl@dailyma...|  male|       Dallas|[+1 234 767 8901,...|    [3]|       true|      900.0|   2021-02-14|2021-02-10 01:15:00|\n|  5|      Kurt|        Rome|krome4@shutterfly...|female|         null|[+1 817 934 7142,...|     []|      false|       null|         null|2021-04-02 00:55:18|\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|       Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n|  4|     Ashby|    MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["users_df.\\\n    select('id','customer_from').\\\n    orderBy(col('customer_from')).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1e9fc2df-1b54-42ea-bae0-af85114f161f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+---+-------------+\n| id|customer_from|\n+---+-------------+\n|  4|         null|\n|  5|         null|\n|  1|   2021-01-15|\n|  3|   2021-01-21|\n|  2|   2021-02-14|\n+---+-------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+-------------+\n| id|customer_from|\n+---+-------------+\n|  4|         null|\n|  5|         null|\n|  1|   2021-01-15|\n|  3|   2021-01-21|\n|  2|   2021-02-14|\n+---+-------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["users_df.\\\n    select('id','customer_from').\\\n    orderBy(col('customer_from').asc_nulls_last()).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a4988201-9e05-4237-8e1a-44ebbc26bd36","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+---+-------------+\n| id|customer_from|\n+---+-------------+\n|  1|   2021-01-15|\n|  3|   2021-01-21|\n|  2|   2021-02-14|\n|  4|         null|\n|  5|         null|\n+---+-------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+-------------+\n| id|customer_from|\n+---+-------------+\n|  1|   2021-01-15|\n|  3|   2021-01-21|\n|  2|   2021-02-14|\n|  4|         null|\n|  5|         null|\n+---+-------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["users_df.\\\n    select('id','customer_from').\\\n    orderBy(col('customer_from').desc()).\\\n    show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fcd79045-7260-4e4d-904a-1a3aa0f30d98","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+---+-------------+\n| id|customer_from|\n+---+-------------+\n|  2|   2021-02-14|\n|  3|   2021-01-21|\n|  1|   2021-01-15|\n|  4|         null|\n|  5|         null|\n+---+-------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+-------------+\n| id|customer_from|\n+---+-------------+\n|  2|   2021-02-14|\n|  3|   2021-01-21|\n|  1|   2021-01-15|\n|  4|         null|\n|  5|         null|\n+---+-------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["users_df.dropDuplicates(subset=[\"is_customer\"]).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"51db34c8-89d1-486e-be4f-4292bbfb98ff","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  4|     Ashby|    MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|       Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n| id|first_name|   last_name|               email|gender| current_city|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n|  4|     Ashby|    MAddocks|   maddocks@home.plk|  male|San Frnasisco|        [null, null]|     []|      false|       null|         null|2021-04-10 17:45:30|\n|  1|    Corrie|Van den Oord|cvandenoorde@etsy...|  male|       Dallas|[+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n+---+----------+------------+--------------------+------+-------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"data manipulations","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":3167292806970606,"dataframes":["_sqldf"]}},"language":"python","widgets":{},"notebookOrigID":3167292806970605}},"nbformat":4,"nbformat_minor":0}
